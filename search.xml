<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Arthas</title>
    <url>/2025/02/09/arthas/arthas/posts/undefined/</url>
    <content><![CDATA[<ul>
<li><p><a href="https://github.com/alibaba/arthas/issues/71">Arthas的一些特殊用法文档说明 · Issue #71 · alibaba&#x2F;arthas</a></p>
</li>
<li><p><a href="https://github.com/alibaba/arthas/issues/1424">arthas 获取spring被代理的目标对象 · Issue #1424 · alibaba&#x2F;arthas</a></p>
</li>
<li><p><a href="https://github.com/alibaba/arthas/issues/537">Arthas实践–jad&#x2F;mc&#x2F;redefine线上热更新一条龙 · Issue #537 · alibaba&#x2F;arthas</a></p>
</li>
</ul>
<h3 id="1-获取当前HttpServletRequest"><a href="#1-获取当前HttpServletRequest" class="headerlink" title="1. 获取当前HttpServletRequest"></a>1. 获取当前HttpServletRequest</h3><ul>
<li><p>执行某个request方法</p>
<p>  <code>@org.springframework.web.context.request.RequestContextHolder@currentRequestAttributes().getRequest().xxx</code></p>
</li>
<li><p>获取全部的请求头</p>
<p>  <code>@org.springframework.web.context.request.RequestContextHolder@currentRequestAttributes().getRequest().getHeaderNames()</code></p>
</li>
</ul>
<h3 id="2-获取spring-context-并执行某些操作"><a href="#2-获取spring-context-并执行某些操作" class="headerlink" title="2. 获取spring context 并执行某些操作"></a>2. 获取spring context 并执行某些操作</h3><blockquote>
<p><strong>前置</strong> 使用tt记录请求，获取到上下文</p>
<p>tt -t org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter invokeHandlerMethod -n 3</p>
</blockquote>
<pre><code>tt -i 1000 -w &#39;target.getApplicationContext().getBean(&quot;jdbcTemplate&quot;)&#39;

tt -i 1000 -w &#39;target.getApplicationContext().getBean(&quot;jdbcTemplate&quot;).dataSource.ConnectionPool&#39;

tt -i 1000 -w &#39;target.getApplicationContext().getBean(&quot;jdbcTemplate&quot;).getTargetSource().target&#39;

tt -i 1000 -w &#39;target.getApplicationContext().getBean(&quot;jdbcTemplate&quot;).getTargetSource().target.cacheMap&#39;

tt -i 1000  -w &#39;target.getApplicationContext().getEnvironment().getProperty(&quot;spring.datasource.riskctrl.url&quot;)&#39;
</code></pre>
<h3 id="3-使用ognl"><a href="#3-使用ognl" class="headerlink" title="3. 使用ognl"></a>3. 使用<a href="https://commons.apache.org/dormant/commons-ognl/language-guide.html">ognl</a></h3><ul>
<li><p>对前置表达式值进行二次计算  #this 表示前置表达式的值 <strong><code>.()</code></strong> 表示自表达式，产生一个单一值</p>
<p>  <strong><code>listeners.size().(#this &gt; 100? 2\*#this : 20+#this)</code></strong></p>
</li>
<li><p>对前置表达式进行二次计算，产生一个数组</p>
<p>  <strong><code>params[0].&#123;#this == &quot;lei&quot; ?  &quot;yes&quot; : &quot;no&quot;&#125;</code></strong></p>
</li>
<li><p>对前置表达式(数组类型)进行二次计算，产生一个新的数组</p>
<p>  <strong><code>params.&#123;#this instanceof String ?  &quot;yes&quot; : &quot;no&quot;&#125;</code></strong></p>
</li>
<li><p>返回数组中第一个匹配的对象</p>
<p>  <strong><code>params.&#123;^#this instanceof Integer&#125;</code></strong></p>
</li>
<li><p>调用static方法 使用  <strong>@class@method(<strong><strong>args</strong></strong>)</strong></p>
<p>  <strong><code>@org.springframework.web.context.request.RequestContextHolder@currentRequestAttributes()</code></strong></p>
</li>
<li><p>获取静态字段 <strong>@class@field</strong></p>
</li>
</ul>
<h3 id="4-一些常用命令"><a href="#4-一些常用命令" class="headerlink" title="4. 一些常用命令"></a>4. 一些常用命令</h3><ul>
<li><p>获取classloader hash，如果是springBoot项目取 org.springframework.boot.loader.LaunchedURLClassLoader</p>
<p>  <strong><code>classloader -t</code></strong></p>
</li>
<li><p>容器安装 vim</p>
<p>  <strong><code>apt-get update &amp;&amp; apt-get install -y vim</code></strong></p>
</li>
<li><p>Ognl 获取spring context</p>
  <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 49c2faae 表示classloader hash</span><br><span class="line"># cn.hutool.extra.spring.SpringUtil 表示能获取到spring容器的方法</span><br><span class="line">ognl -c 49c2faae &#x27;#beanName=&quot;eventDataAuthManage&quot;, #bean=@cn.hutool.extra.spring.SpringUtil@getBean(#beanName), @org.springframework.aop.support.AopUtils@getTargetClass(#bean).getName()&#x27;</span><br></pre></td></tr></table></figure>
</li>
<li><p>Ognl lambda 表达式</p>
  <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">-- 使用 =:[] 定义lambda即函数</span><br><span class="line">-- 使用 #getBean() 调用</span><br><span class="line">ognl -c 49c2faae &#x27;</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">getBean =:[@cn.hutool.extra.spring.SpringUtil@getBean(#this)],</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">getBean(<span class="string">&quot;syncDataAuthController&quot;</span>).dataCodeList<span class="string">&#x27;</span></span></span><br></pre></td></tr></table></figure>
</li>
<li><p>查找方法</p>
<p>  <strong><code>sm com.xx.class</code></strong></p>
</li>
<li><p>修改静态变量的值</p>
<p>  <strong><code>getstatic com.xyz.HelloWorld s &quot;#s=&#39;abc&#39;&quot;</code></strong></p>
</li>
<li><p>修改变量的值</p>
  <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">-- 1. 使用 tt 记录方法调用</span><br><span class="line">tt -t com.example.UserService getUserById</span><br><span class="line">-- 2. 查看记录</span><br><span class="line">tt -l</span><br><span class="line">-- 3. 修改捕获的对象 target 代表当前被调用方法的对象实例（即 &quot;this&quot; 对象）</span><br><span class="line">tt -i 1000 -w &#x27;target.name=&quot;newName&quot;&#x27;</span><br></pre></td></tr></table></figure>
</li>
<li><p>过滤参数类型为class的方法</p>
  <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">-- 过滤要点就是通过全类名@class拿到class对象，再getName()获取名称</span><br><span class="line">watch com.wangji92.arthas.plugin.demo.controller.StaticTest invokeClass &#x27;&#123;returnObj,throwExp&#125;&#x27;  -n 5  -x 3  </span><br><span class="line">&#x27;params[0].getName().equals(@com.wangji92.arthas.plug.demo.controller.User@class.getName())&#x27; -v</span><br></pre></td></tr></table></figure>
</li>
<li><p>查找response404的堆栈</p>
  <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">stack -E javax.servlet.http.HttpServletResponse sendError|setStatus params[0]==404</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="5-特殊命令"><a href="#5-特殊命令" class="headerlink" title="5. 特殊命令"></a>5. 特殊命令</h3><ul>
<li><p>Trace 命令多个类、多个方法、指定线程、指定耗时时间</p>
  <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># trace -E 表示正则</span><br><span class="line">trace -E </span><br><span class="line"># 表示类是 NioEventLoop 或者 SingleThreadEventExecutor</span><br><span class="line">&#x27;io\.netty\.channel\.nio\.NioEventLoop|io\.netty\.util\.concurrent\.SingleThreadEventExecutor&#x27;  </span><br><span class="line"># 表示方法是 select processSelectedKeys runAllTasks</span><br><span class="line">&#x27;select|processSelectedKeys|runAllTasks&#x27; </span><br><span class="line"># @Thread arthas提供表示当前线程 #cost arthas提供，表示耗时</span><br><span class="line">&#x27;@Thread@currentThread().getName().contains(&quot;IO-HTTP-WORKER-IOPool&quot;)&amp;&amp;#cost&gt;500&#x27;</span><br></pre></td></tr></table></figure>
</li>
<li><p>获取代理对象的原始对象</p>
  <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tt -w &#x27;#isProxy=:[ @org.springframework.aop.support.AopUtils@isAopProxy(#this)?1: #this instanceof java.lang.reflect.Proxy ? 0 :-1],#isJdkDynamicProxy =:[@org.springframework.aop.support.AopUtils@isJdkDynamicProxy(#this) ? true :false ],#cglibTarget =:[#hField =#this.getClass().getDeclaredField(&quot;CGLIB$CALLBACK_0&quot;),#hField.setAccessible(true),#dynamicAdvisedInterceptor=#hField.get(#this),#fieldAdvised=#dynamicAdvisedInterceptor.getClass().getDeclaredField(&quot;advised&quot;),#fieldAdvised.setAccessible(true),1==1? #fieldAdvised.get(#dynamicAdvisedInterceptor).getTargetSource().getTarget():null],#jdkTarget=:[ #hField=#this.getClass().getSuperclass().getDeclaredField(&quot;h&quot;),#hField.setAccessible(true),#aopProxy=#hField.get(#this),#advisedField=#aopProxy.getClass().getDeclaredField(&quot;advised&quot;),#advisedField.setAccessible(true),1==1?#advisedField.get(#aopProxy).getTargetSource().getTarget():null],#nonProxyResultFunc = :[#proxyResul=#isProxy(#this),#proxyResul== -1 ?#this :#proxyResul== 0? @java.lang.reflect.Proxy@getInvocationHandler(#this):#isJdkDynamicProxy(#this)? #isJdkDynamicProxy(#this) : #cglibTarget(#this)],#nonProxyTarget=#nonProxyResultFunc(target),#nonProxyTarget&#x27;  -x 1 -i 1002</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="6-Vmtool-使用"><a href="#6-Vmtool-使用" class="headerlink" title="6. Vmtool 使用"></a>6. Vmtool 使用</h3><blockquote>
<p><code>vmtool</code> 利用 Java 的 Instrumentation API 和 JVM TI（JVM Tool Interface）与 JVM 进行交互，可以绕过spring context 直接获取对象</p>
</blockquote>
<ul>
<li><p>常用子命令</p>
<ul>
<li><code>--action getInstances</code>：获取类的实例</li>
<li><code>--action forceGc</code>：强制执行垃圾回收</li>
<li><code>--action getClassLoader</code>：获取类加载器信息</li>
</ul>
</li>
<li><p>com.xxx.cache.CacheAspect 中的 boolean 变量 cacheEnabled 修改为false</p>
  <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vmtool: Arthas 的一个命令，用于对 JVM 进行底层操作。</span><br><span class="line">-x 3: 设置执行次数限制为 3 次。</span><br><span class="line">--action getInstances: 指定操作为获取类的实例。</span><br><span class="line">--className com.xxx.cache.CacheAspect: 指定要操作的类名。</span><br><span class="line">--express: 后面跟着的是要执行的 OGNL 表达式</span><br><span class="line">ongl表达式:</span><br><span class="line">反射获取字段 #field=instances[0].getClass().getDeclaredField(&quot;cacheEnabled&quot;)</span><br><span class="line">设置为true #field.setAccessible(true)</span><br><span class="line">修改字段 #field.set(instances[0],false)</span><br><span class="line"></span><br><span class="line">vmtool -x 3 --action getInstances --className com.xxx.cache.CacheAspect --express &#x27;#field=instances[0].getClass().getDeclaredField(&quot;cacheEnabled&quot;),#field.setAccessible(true),#field.set(instances[0],false)&#x27; -c 3bd94634</span><br></pre></td></tr></table></figure>
</li>
<li><p>修改final变量</p>
  <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vmtool -x 4 --action getInstances --className com.wangji92.arthas.plugin.demo.controller.CommonController  --express &#x27;#field=instances[0].getClass().getDeclaredField(&quot;FINAL_VALUE&quot;),#modifiers=#field.getClass().getDeclaredField(&quot;modifiers&quot;),#modifiers.setAccessible(true),#modifiers.setInt(#field,#field.getModifiers() &amp; ~@java.lang.reflect.Modifier@FINAL),#field.setAccessible(true),#field.set(instances[0],&quot; 3333&quot;)&#x27; -c  18b4aac2</span><br></pre></td></tr></table></figure>
</li>
<li><p>执行某个方法</p>
  <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vmtool -x 1 --action getInstances </span><br><span class="line">--className com.xx.SyncDataAuthController </span><br><span class="line">--express &#x27;instances[0].getDataCodePage(@com.xx.UtilJson@convertValue(&quot;&#123;\&quot;pageIndex\&quot;:0,\&quot;pageSize\&quot;:0&#125;&quot;, @com.xx.BaseQuery@class))&#x27;</span><br><span class="line">-c 49c2faae</span><br></pre></td></tr></table></figure>
</li>
<li><p>获取spring context</p>
  <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vmtool --action getInstances --className org.springframework.context.ConfigurableApplicationContext --express &#x27;instances[0].getEnvironment().getProperty(&quot;server.port&quot;)&#x27;</span><br></pre></td></tr></table></figure></li>
</ul>
]]></content>
      <categories>
        <category>Arthas</category>
      </categories>
      <tags>
        <tag>Arthas</tag>
        <tag>问题排查</tag>
      </tags>
  </entry>
  <entry>
    <title>Feign 更换 Client</title>
    <url>/2025/02/09/feign/feign-geng-huan-client/posts/undefined/</url>
    <content><![CDATA[<h2 id="基于-loadBalancer-更换-FeignClient-为-vertx-web-实现"><a href="#基于-loadBalancer-更换-FeignClient-为-vertx-web-实现" class="headerlink" title="基于 loadBalancer 更换 FeignClient 为 vertx-web 实现"></a>基于 loadBalancer 更换 FeignClient 为 vertx-web 实现</h2><ul>
<li>feignClient 实现类依旧是 LoadBalancerFeignClient</li>
<li>LoadBalancerFeignClient 中 delegate 更换为自定义实现的 vertx-web-client</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">VertxFeignClient</span> <span class="keyword">implements</span> <span class="title class_">Client</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> WebClient webClient;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">VertxFeignClient</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="type">Vertx</span> <span class="variable">vertx</span> <span class="operator">=</span> Vertx.vertx();</span><br><span class="line">        <span class="type">WebClientOptions</span> <span class="variable">webClientOptions</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">WebClientOptions</span>()</span><br><span class="line">                .setMaxPoolSize(<span class="number">100</span>)</span><br><span class="line">                .setMaxWaitQueueSize(<span class="number">10000</span>);</span><br><span class="line">        <span class="built_in">this</span>.webClient = WebClient.create(vertx, webClientOptions);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> Response <span class="title function_">execute</span><span class="params">(Request request, Request.Options options)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">String</span> <span class="variable">url</span> <span class="operator">=</span> request.url();</span><br><span class="line">        <span class="type">var</span> <span class="variable">bodys</span> <span class="operator">=</span> request.requestBody().asBytes();</span><br><span class="line">        Map&lt;String, Collection&lt;String&gt;&gt; headers = request.headers();</span><br><span class="line">        io.vertx.core.http.<span class="type">HttpMethod</span> <span class="variable">vertxMethod</span> <span class="operator">=</span> io.vertx.core.http.HttpMethod.valueOf(request.httpMethod().name());</span><br><span class="line"></span><br><span class="line">        <span class="type">HeadersMultiMap</span> <span class="variable">entries</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">HeadersMultiMap</span>();</span><br><span class="line">        headers.forEach(entries::add);</span><br><span class="line"></span><br><span class="line">        CompletableFuture&lt;Response&gt; completableFuture = <span class="keyword">new</span> <span class="title class_">CompletableFuture</span>&lt;&gt;();</span><br><span class="line"></span><br><span class="line">        webClient.requestAbs(vertxMethod, url)</span><br><span class="line">                .putHeaders(entries)</span><br><span class="line">                .sendBuffer(bodys == <span class="literal">null</span> ? Buffer.buffer() : Buffer.buffer(bodys))</span><br><span class="line">                .timeout(options.readTimeoutMillis(), TimeUnit.MILLISECONDS)</span><br><span class="line">                .onSuccess(t -&gt; &#123;</span><br><span class="line">                    log.info(<span class="string">&quot;url[&#123;&#125;] 响应 -&gt; &#123;&#125;&quot;</span>, url, t.bodyAsString());</span><br><span class="line">                    <span class="type">MultiMap</span> <span class="variable">responseHeaders</span> <span class="operator">=</span> t.headers();</span><br><span class="line">                    Map&lt;String, Collection&lt;String&gt;&gt; map = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;&gt;();</span><br><span class="line">                    responseHeaders.forEach((k, v) -&gt; map.put(k, Collections.singleton(v)));</span><br><span class="line">                    completableFuture.complete(Response.builder()</span><br><span class="line">                            .status(t.statusCode())</span><br><span class="line">                            .reason(t.statusMessage())</span><br><span class="line">                            .headers(map)</span><br><span class="line">                            .body(t.bodyAsBuffer().getBytes())</span><br><span class="line">                            .request(request)</span><br><span class="line">                            .build());</span><br><span class="line">                &#125;).onFailure(completableFuture::completeExceptionally);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> completableFuture.get();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException | ExecutionException e) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">RuntimeException</span>(e);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>配置类装配 FeignClient bean</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">VertxFeignClientConfiguration</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="meta">@Primary</span></span><br><span class="line">    <span class="keyword">public</span> Client <span class="title function_">feignClient</span><span class="params">(CachingSpringLoadBalancerFactory cachingFactory,</span></span><br><span class="line"><span class="params">                              SpringClientFactory clientFactory)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">LoadBalancerFeignClient</span>(<span class="keyword">new</span> <span class="title class_">VertxFeignClient</span>(), cachingFactory, clientFactory);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>feign</category>
      </categories>
      <tags>
        <tag>feign</tag>
        <tag>rpc</tag>
        <tag>微服务</tag>
      </tags>
  </entry>
  <entry>
    <title>Feign、Hystrix、Ribbon 超时机制</title>
    <url>/2025/02/09/feign/feign-hystrix-ribbon-chao-shi-ji-zhi/posts/undefined/</url>
    <content><![CDATA[<h2 id="使用版本"><a href="#使用版本" class="headerlink" title="使用版本"></a>使用版本</h2><ul>
<li><p>open-feign、hystrix、ribbon: 2.1.0.RELEASE</p>
</li>
<li><p>feign-okhttp: 10.1.0</p>
</li>
<li><p>archaius: 0.7.6</p>
</li>
<li><p>jackson: 2.17.0</p>
</li>
</ul>
<h2 id="前置条件"><a href="#前置条件" class="headerlink" title="前置条件"></a>前置条件</h2><ul>
<li>feign.okhttp.enabled&#x3D;true   #feign 使用 OkHttpClient 作为 http 请求框架</li>
<li>feign.hystrix.enabled&#x3D;true   #开启 hystrix</li>
</ul>
<h2 id="关系图"><a href="#关系图" class="headerlink" title="关系图"></a>关系图</h2><p><img data-src="/images/feign/01.png" alt="img"></p>
<h2 id="超时机制"><a href="#超时机制" class="headerlink" title="超时机制"></a>超时机制</h2><h3 id="hystrix-超时"><a href="#hystrix-超时" class="headerlink" title="hystrix 超时"></a>hystrix 超时</h3><ul>
<li>最上层是 hystrix 超时，hystrix 会异步提交一个延时任务，延时时间就是配置的超时时间</li>
<li>配置 hystrix 全局的超时时间</li>
</ul>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">hystrix:</span></span><br><span class="line">  <span class="attr">command:</span></span><br><span class="line">    <span class="comment"># 默认的配置，如果没有独立配置，那么这个会是默认的配置</span></span><br><span class="line">    <span class="attr">default:</span></span><br><span class="line">      <span class="attr">execution:</span></span><br><span class="line">        <span class="attr">isolation:</span></span><br><span class="line">          <span class="attr">thread:</span></span><br><span class="line">            <span class="attr">timeoutInMilliseconds:</span> <span class="number">6000</span></span><br></pre></td></tr></table></figure>

<ul>
<li>[配置文件]配置具体接口的超时时间，${commandKey} 表示 commandKey，比如接口位于类 HttpBinFeign，方法名为 delay_3（），则 commandKey&#x3D;HttpBinFeign#delay_3（）；默认会优先读取具体接口的配置，具体接口的配置不存在则会使用默认的配置</li>
</ul>
<figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="attr">hystrix.command.$&#123;commandKey&#125;.execution.isolation.thread.timeoutInMilliseconds</span>=<span class="string">4000</span></span><br></pre></td></tr></table></figure>

<p><img data-src="/images/feign/02.png" alt="img"></p>
<p><img data-src="/images/feign/03.png" alt="img"></p>
<ul>
<li><p>[@HystrixCommand]配置具体接口的超时时间</p>
<ol>
<li>启用切面</li>
</ol>
  <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">HystrixConfiguration</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="keyword">public</span> HystrixCommandAspect <span class="title function_">hystrixCommandAspect</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">HystrixCommandAspect</span>();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>@HystrixCommand 配置，这里用了种取巧的方式，添加上此注解会先转换为 HystrixCommandProperties，然后当 Feign 接口封装为 hystrixCommand 时就会从 factory 中根据 cacheKey 获取，cacheKey 就是 commandKey，所以只需要保证在 feign 接口前面组装此配置就行。这里是取巧的方式，不确定会有什么问题- _ -</li>
</ol>
  <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@HystrixCommand(</span></span><br><span class="line"><span class="meta">        commandKey = &quot;HttpBinFeign#delay_3()&quot;,</span></span><br><span class="line"><span class="meta">        commandProperties = &#123;</span></span><br><span class="line"><span class="meta">                @HystrixProperty(name = &quot;execution.isolation.thread.timeoutInMilliseconds&quot;, value = &quot;2000&quot;)</span></span><br><span class="line"><span class="meta">        &#125;</span></span><br><span class="line"><span class="meta">)</span></span><br><span class="line"><span class="keyword">public</span> String <span class="title function_">delay_3</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> httpBinFeign.delay_3();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<p><img data-src="/images/feign/04.png" alt="img"></p>
<h3 id="feign、ribbon-超时配置"><a href="#feign、ribbon-超时配置" class="headerlink" title="feign、ribbon 超时配置"></a>feign、ribbon 超时配置</h3><ul>
<li>feign 未配置时，请求超时按 ribbon 配置；若配置了 feign 超时，则请求超时按 feign 配置</li>
<li>feign 全局超时配置，<strong>注意 connect-timeout 与 read-timeout 两个配置都需要配置</strong>，单独配置不生效</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">feign:</span><br><span class="line">  client:</span><br><span class="line">    config:</span><br><span class="line">      # 默认配置</span><br><span class="line">      <span class="keyword">default</span>:</span><br><span class="line">        connect-timeout: <span class="number">1000</span></span><br><span class="line">        read-timeout: <span class="number">5000</span></span><br></pre></td></tr></table></figure>

<p><img data-src="/images/feign/05.png" alt="img"></p>
<ul>
<li><p>单个 feign 接口超时配置</p>
<ol>
<li>优先级： 配置分为 3 种，分别是代码配置、默认配置、单个接口配置文件配置；</li>
</ol>
<p>  默认情况下（feign.client.defaultToProperties&#x3D;true） 时配置优先级为 代码配置 -&gt; 默认配置 -&gt; 单个接口配置文件配置，优先级从低到高，高优先级的会覆盖低优先级的；</p>
<p>  feign.client.defaultToProperties&#x3D;false 时配置优先级为 默认配置 -&gt; 单个接口配置文件配置 -&gt; 代码配置；</p>
<p>  也就是说默认情况下代码配置会被默认配置覆盖，所以如果想要针对单个接口进行配置，必须要使用配置文件进行配置；当然也可以设置 feign.client.defaultToProperties&#x3D;false，这样代码配置的优先级最高</p>
<p>  <img data-src="/images/feign/06.png" alt="img"></p>
<ol start="2">
<li>单个接口配置</li>
</ol>
  <figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 这里的httpbin代表的是FeignClient中的contextId</span></span><br><span class="line"><span class="attr">feign.client.config.httpbin.read-timeout</span>=<span class="string">2500</span></span><br><span class="line"><span class="attr">feign.client.config.httpbin.connect-timeout</span>=<span class="string">800</span></span><br></pre></td></tr></table></figure>

<ol start="3">
<li>单个接口代码配置，注意配置类不能使用@component 注解，否则会全局生效</li>
</ol>
  <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CustomFeignConfiguration</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="keyword">public</span> Request.Options <span class="title function_">request</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">Request</span>.Options(<span class="number">1000</span>, <span class="number">3000</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@FeignClient(name = &quot;service-httpbin&quot;</span></span><br><span class="line"><span class="meta">        , contextId = &quot;httpbin&quot;, configuration = CustomFeignConfiguration.class</span></span><br><span class="line"><span class="meta">)</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>ribbon 全局配置</p>
</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">ribbon:</span><br><span class="line">  ReadTimeout: <span class="number">5000</span> # 请求处理的超时时间</span><br><span class="line">  ConnectTimeout: <span class="number">2000</span> # 请求连接超时时间</span><br><span class="line">  # 以下两个重试配置表示同一个接口最多调用<span class="number">2</span>次，且第二次重试不在同一个实例上</span><br><span class="line">  MaxAutoRetries: <span class="number">0</span> #同一台实例最大重试次数,不包括首次调用</span><br><span class="line">  MaxAutoRetriesNextServer: <span class="number">1</span> # 切换实例的重试次数</span><br><span class="line">  OkToRetryOnAllOperations: <span class="literal">false</span> #重试操作，<span class="literal">false</span>表示只会对get接口进行重试</span><br></pre></td></tr></table></figure>

<h3 id="非负载均衡下调用"><a href="#非负载均衡下调用" class="headerlink" title="非负载均衡下调用"></a>非负载均衡下调用</h3><ul>
<li>feignClient 指定 url 则不会走 loadbalancer 调用，会直接使用 okHttpClient 进行调用，参考关系图中[1]</li>
<li>OkHttpClient 默认超时配置如下</li>
</ul>
<p><img data-src="/images/feign/07.png" alt="img"></p>
<ul>
<li>若配置了 feign 接口超时，则会覆盖 okHttpClient 配置</li>
</ul>
<p><img data-src="/images/feign/08.png" alt="img"></p>
<h3 id="负载均衡下的调用"><a href="#负载均衡下的调用" class="headerlink" title="负载均衡下的调用"></a>负载均衡下的调用</h3><ul>
<li>feignClient 未指定 url 时会根据 name 找到对应的服务，走 loadbalancer 调用，参考关系图中[2]</li>
<li>若指定了 feign 超时配置，则使用 feign 超时配置，否则使用 ribbon 超时配置</li>
</ul>
<p><img data-src="/images/feign/09.png" alt="img"></p>
<h3 id="超时机制总结"><a href="#超时机制总结" class="headerlink" title="超时机制总结"></a>超时机制总结</h3><ol>
<li>Hystrix 配置的超时时间需要大于 feign &amp; ribbon 配置的超时时间</li>
<li>由于 ribbon 有重试机制，所以 hystrix 配置的超时时间需要大于单个请求超时时间 * 请求的总次数（<strong>MaxAutoRetries+ 1）*（MaxAutoRetriesNextServer+1</strong>） </li>
<li>只要配置了 feign 超时，那么无论是 Okhttp 还是 ribbon 的超时都会被覆盖</li>
<li>feign 超时需要同时配置 connectTimeout &amp; readTimeout</li>
<li>建议 hystrix、feign、ribbon 都配置默认的超时时间，且 hystrix 超时时间 &gt; feign &#x3D;&#x3D; ribbon</li>
<li>针对独立接口的配置，需要注意 hystrix、feign 超时都需要配置</li>
</ol>
<h2 id="定制-CachingSpringLoadBalancerFactory，实现负载均衡到本地服务上"><a href="#定制-CachingSpringLoadBalancerFactory，实现负载均衡到本地服务上" class="headerlink" title="定制 CachingSpringLoadBalancerFactory，实现负载均衡到本地服务上"></a>定制 CachingSpringLoadBalancerFactory，实现负载均衡到本地服务上</h2><h3 id="自定义-CachingSpringLoadBalancerFactory，给所有服务添加本地地址"><a href="#自定义-CachingSpringLoadBalancerFactory，给所有服务添加本地地址" class="headerlink" title="自定义 CachingSpringLoadBalancerFactory，给所有服务添加本地地址"></a>自定义 CachingSpringLoadBalancerFactory，给所有服务添加本地地址</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">LocalCachingSpringLoadBalancerFactory</span> <span class="keyword">extends</span> <span class="title class_">CachingSpringLoadBalancerFactory</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">volatile</span> Map&lt;String, FeignLoadBalancer&gt; cache = <span class="keyword">new</span> <span class="title class_">ConcurrentReferenceHashMap</span>&lt;&gt;();</span><br><span class="line">    <span class="keyword">private</span> String localHost;</span><br><span class="line">    <span class="keyword">private</span> Integer localPort;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">LocalCachingSpringLoadBalancerFactory</span><span class="params">(SpringClientFactory factory, String localHost, Integer localPort)</span> &#123;</span><br><span class="line">        <span class="built_in">super</span>(factory);</span><br><span class="line">        <span class="built_in">this</span>.localHost = localHost;</span><br><span class="line">        <span class="built_in">this</span>.localPort = localPort;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> FeignLoadBalancer <span class="title function_">create</span><span class="params">(String clientName)</span> &#123;</span><br><span class="line">        <span class="type">FeignLoadBalancer</span> <span class="variable">client</span> <span class="operator">=</span> <span class="built_in">this</span>.cache.get(clientName);</span><br><span class="line">        <span class="keyword">if</span>(client != <span class="literal">null</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> client;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="type">IClientConfig</span> <span class="variable">config</span> <span class="operator">=</span> <span class="built_in">this</span>.factory.getClientConfig(clientName);</span><br><span class="line">        <span class="type">ILoadBalancer</span> <span class="variable">lb</span> <span class="operator">=</span> <span class="built_in">this</span>.factory.getLoadBalancer(clientName);</span><br><span class="line">        <span class="comment">// 添加本地地址</span></span><br><span class="line">        lb.addServers(Lists.newArrayList(<span class="keyword">new</span> <span class="title class_">Server</span>(<span class="built_in">this</span>.localHost, <span class="built_in">this</span>.localPort)));</span><br><span class="line">        <span class="type">ServerIntrospector</span> <span class="variable">serverIntrospector</span> <span class="operator">=</span> <span class="built_in">this</span>.factory.getInstance(clientName, ServerIntrospector.class);</span><br><span class="line">        client = loadBalancedRetryFactory != <span class="literal">null</span> ? <span class="keyword">new</span> <span class="title class_">RetryableFeignLoadBalancer</span>(lb, config, serverIntrospector,</span><br><span class="line">                loadBalancedRetryFactory) : <span class="keyword">new</span> <span class="title class_">FeignLoadBalancer</span>(lb, config, serverIntrospector);</span><br><span class="line">        <span class="built_in">this</span>.cache.put(clientName, client);</span><br><span class="line">        <span class="keyword">return</span> client;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="注入-bean，覆盖默认的配置-FeignRibbonClientAutoConfiguration"><a href="#注入-bean，覆盖默认的配置-FeignRibbonClientAutoConfiguration" class="headerlink" title="注入 bean，覆盖默认的配置 FeignRibbonClientAutoConfiguration"></a>注入 bean，覆盖默认的配置 FeignRibbonClientAutoConfiguration</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">LocalRibbonConfiguration</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Value(&quot;$&#123;server.local.host:127.0.0.1&#125;&quot;)</span></span><br><span class="line">    <span class="keyword">private</span> String localHost;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Value(&quot;$&#123;server.local.port:8000&#125;&quot;)</span></span><br><span class="line">    <span class="keyword">private</span> Integer localPort;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="meta">@Primary</span></span><br><span class="line">    <span class="keyword">public</span> CachingSpringLoadBalancerFactory <span class="title function_">cachingLBClientFactory</span><span class="params">(</span></span><br><span class="line"><span class="params">            SpringClientFactory factory)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">LocalCachingSpringLoadBalancerFactory</span>(factory, localHost, localPort);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="使用-BeanPostProcessor-修改-LoadBalancerFeignClient-中的-CachingSpringLoadBalancerFactory"><a href="#使用-BeanPostProcessor-修改-LoadBalancerFeignClient-中的-CachingSpringLoadBalancerFactory" class="headerlink" title="使用 BeanPostProcessor 修改 LoadBalancerFeignClient 中的 CachingSpringLoadBalancerFactory"></a>使用 BeanPostProcessor 修改 LoadBalancerFeignClient 中的 CachingSpringLoadBalancerFactory</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">LocalCachingSpringLoadBalancerFactoryBeanPostProcessor</span> <span class="keyword">implements</span> <span class="title class_">BeanPostProcessor</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> String localHost;</span><br><span class="line">    <span class="keyword">private</span> Integer localPort;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">LocalCachingSpringLoadBalancerFactoryBeanPostProcessor</span><span class="params">(String localHost, Integer localPort)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.localHost = localHost;</span><br><span class="line">        <span class="built_in">this</span>.localPort = localPort;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> Object <span class="title function_">postProcessAfterInitialization</span><span class="params">(Object bean, String beanName)</span> <span class="keyword">throws</span> BeansException &#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (bean <span class="keyword">instanceof</span> LoadBalancerFeignClient) &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                <span class="type">var</span> <span class="variable">loadBalancerFeignClient</span> <span class="operator">=</span> (LoadBalancerFeignClient) bean;</span><br><span class="line">                <span class="type">Field</span> <span class="variable">lbClientFactory</span> <span class="operator">=</span> FieldUtils.getDeclaredField(LoadBalancerFeignClient.class, <span class="string">&quot;lbClientFactory&quot;</span>, <span class="literal">true</span>);</span><br><span class="line">                lbClientFactory.setAccessible(<span class="literal">true</span>);</span><br><span class="line">                <span class="type">var</span> <span class="variable">clientFactory</span> <span class="operator">=</span> FieldUtils.getDeclaredField(LoadBalancerFeignClient.class, <span class="string">&quot;clientFactory&quot;</span>, <span class="literal">true</span>);</span><br><span class="line">                clientFactory.setAccessible(<span class="literal">true</span>);</span><br><span class="line">                <span class="comment">// 获取到 springClientFactory</span></span><br><span class="line">                <span class="type">var</span> <span class="variable">springClientFactory</span> <span class="operator">=</span> (SpringClientFactory) clientFactory.get(loadBalancerFeignClient);</span><br><span class="line">                <span class="comment">// 构建local</span></span><br><span class="line">                <span class="type">LocalCachingSpringLoadBalancerFactory</span> <span class="variable">cachingSpringLoadBalancerFactory</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">LocalCachingSpringLoadBalancerFactory</span>(springClientFactory, localHost, localPort);</span><br><span class="line">                <span class="comment">// 设置到值里面</span></span><br><span class="line">                lbClientFactory.set(loadBalancerFeignClient, cachingSpringLoadBalancerFactory);</span><br><span class="line">            &#125; <span class="keyword">catch</span> (IllegalAccessException e) &#123;</span><br><span class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">RuntimeException</span>(e);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> bean;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>feign</category>
      </categories>
      <tags>
        <tag>feign</tag>
        <tag>rpc</tag>
        <tag>微服务</tag>
      </tags>
  </entry>
  <entry>
    <title>LoadBalancerClient 自定义</title>
    <url>/2025/02/09/feign/loadbalancerclient-zi-ding-yi/posts/undefined/</url>
    <content><![CDATA[<h2 id="自定义路由信息"><a href="#自定义路由信息" class="headerlink" title="自定义路由信息"></a>自定义路由信息</h2><blockquote>
<p>日常开发中 loadBalancer 一般是基于服务发现，不需要我们显示的指定；某些场景下（比如单元测试、联调）需要我们自定义 LoadBalancerClient，不走默认的服务发现，而是自定义路由信息</p>
</blockquote>
<ul>
<li><code>LoadBalancerClient</code> 默认的配置是 <code>LoadBalancerClientConfiguration</code></li>
<li>仿造 <code>LoadBalancerClientConfiguration</code> 实现自己的配置</li>
</ul>
<blockquote>
<p>由于<code>LoadBalancerClientConfiguration</code>也是基于 NamedContextFactory，所以我们只需要实现需要修改的配置，其他配置会默认读取<code>LoadBalancerClientConfiguration</code></p>
<p>比如下面的代码中，自定义了服务路由信息，会根据配置返回服务的路由信息</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">UserServiceLoadBalanceConfiguration</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="keyword">public</span> ReactorLoadBalancer&lt;ServiceInstance&gt; <span class="title function_">reactorServiceInstanceLoadBalancer</span><span class="params">(Environment environment,</span></span><br><span class="line"><span class="params">                                                                                   LoadBalancerClientFactory loadBalancerClientFactory)</span> &#123;</span><br><span class="line">        <span class="comment">// 获取当前 loadBalance 的 client name</span></span><br><span class="line">        <span class="comment">// 由于此配置用在 UserRegistrationService 上，所以这里默认 = user-service</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">name</span> <span class="operator">=</span> environment.getProperty(LoadBalancerClientFactory.PROPERTY_NAME);</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">RoundRobinLoadBalancer</span>(</span><br><span class="line">                <span class="comment">// 这里相当于根据这个name，找到对应的子context，从里面获取到 ServiceInstanceListSupplier 对应的bean</span></span><br><span class="line">                <span class="comment">// 也就是相当于这个 UserRegistrationServiceLoadBalanceConfiguration 下配置的 ServiceInstanceListSupplier -&gt; 也就是 ServiceInstanceListSupplier</span></span><br><span class="line">                loadBalancerClientFactory.getLazyProvider(name, ServiceInstanceListSupplier.class),</span><br><span class="line">                name</span><br><span class="line">        );</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="keyword">public</span> ServiceInstanceListSupplier <span class="title function_">userServiceClientServiceInstanceListSupplier</span><span class="params">(</span></span><br><span class="line"><span class="params">            ConfigurableApplicationContext context)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">UserServiceServiceInstanceListSupplier</span>(context.getEnvironment());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">UserServiceServiceInstanceListSupplier</span> <span class="keyword">implements</span> <span class="title class_">ServiceInstanceListSupplier</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Environment environment;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">UserServiceServiceInstanceListSupplier</span><span class="params">(Environment environment)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.environment = environment;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">getServiceId</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> environment.getProperty(<span class="string">&quot;user-service-name&quot;</span>, <span class="string">&quot;user-service&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> Flux&lt;List&lt;ServiceInstance&gt;&gt; <span class="title function_">get</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="type">DefaultServiceInstance</span> <span class="variable">defaultServiceInstance</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">DefaultServiceInstance</span>();</span><br><span class="line">        defaultServiceInstance.setServiceId(getServiceId());</span><br><span class="line">        defaultServiceInstance.setHost(environment.getProperty(<span class="string">&quot;user-service-host&quot;</span>, <span class="string">&quot;127.0.0.1&quot;</span>));</span><br><span class="line">        defaultServiceInstance.setPort(Integer.parseInt(environment.getProperty(<span class="string">&quot;user-service-port&quot;</span>, <span class="string">&quot;8080&quot;</span>)));</span><br><span class="line">        <span class="keyword">return</span> Flux.just(Arrays.asList(defaultServiceInstance));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>使用，注解上指定配置即可</li>
</ul>
<blockquote>
<p>@LoadBalancerClient(name &#x3D; “user-service”, configuration &#x3D; UserServiceLoadBalanceConfiguration.class)</p>
</blockquote>
<ul>
<li>以上就能实现自定义路由的功能</li>
</ul>
]]></content>
      <categories>
        <category>feign</category>
      </categories>
      <tags>
        <tag>feign</tag>
        <tag>rpc</tag>
        <tag>微服务</tag>
      </tags>
  </entry>
  <entry>
    <title>多线程异常处理</title>
    <url>/2025/02/09/java/duo-xian-cheng-yi-chang-chu-li/posts/undefined/</url>
    <content><![CDATA[<blockquote>
<p> 多线程场景下，如果没有显示的捕获异常并处理，那么异常会输出到 System.err 中，导致异常信息丢失</p>
</blockquote>
<h3 id="异常被吞噬的例子"><a href="#异常被吞噬的例子" class="headerlink" title="异常被吞噬的例子"></a>异常被吞噬的例子</h3><ul>
<li>新起线程中抛出异常</li>
</ul>
<blockquote>
<p>由于是新启动的线程，此异常并不会抛到父线程或者调用方上，导致异常被没了- - </p>
</blockquote>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">new</span> <span class="title class_">Thread</span>(() -&gt; &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">RuntimeException</span>(<span class="string">&quot;这是一个异常!&quot;</span>);</span><br><span class="line">&#125;).start();</span><br></pre></td></tr></table></figure>

<ul>
<li>线程池中抛出的异常</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Executors.newFixedThreadPool(<span class="number">1</span>)</span><br><span class="line">        .execute(() -&gt; &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">RuntimeException</span>(<span class="string">&quot;线程池中的异常!&quot;</span>);</span><br><span class="line">        &#125;);</span><br></pre></td></tr></table></figure>

<h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h3><blockquote>
<p>针对上面出现的异常吞噬的例子，有以下解决方案</p>
</blockquote>
<ul>
<li><p>Try catch 显示处理异常</p>
</li>
<li><p>指定<code> Thread.UncaughtExceptionHandler</code></p>
<ul>
<li><p>线程处理</p>
</li>
<li><p>thread.setUncaughtExceptionHandler</p>
</li>
<li><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Thread.<span class="type">UncaughtExceptionHandler</span> <span class="variable">uncaughtExceptionHandler</span> <span class="operator">=</span> (t, e) -&gt; log.error(<span class="string">&quot;[catch error]thread -&gt; &#123;&#125;, e -&gt; &#123;&#125;&quot;</span>, t, e);</span><br><span class="line"><span class="type">Thread</span> <span class="variable">thread</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Thread</span>(() -&gt; &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">RuntimeException</span>(<span class="string">&quot;[catch]这是一个异常!&quot;</span>);</span><br><span class="line">&#125;);</span><br><span class="line">thread.setUncaughtExceptionHandler(uncaughtExceptionHandler);</span><br><span class="line">thread.start();</span><br></pre></td></tr></table></figure>

</li>
<li><p>线程池处理</p>
</li>
<li><p>new ThreadFactoryBuilder().setUncaughtExceptionHandler  线程工厂中设置</p>
</li>
<li><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Thread.<span class="type">UncaughtExceptionHandler</span> <span class="variable">uncaughtExceptionHandler</span> <span class="operator">=</span> (t, e) -&gt; log.error(<span class="string">&quot;[catch error]thread -&gt; &#123;&#125;, e -&gt; &#123;&#125;&quot;</span>, t, e);</span><br><span class="line"><span class="type">Thread</span> <span class="variable">thread</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Thread</span>(() -&gt; &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">RuntimeException</span>(<span class="string">&quot;[catch]这是一个异常!&quot;</span>);</span><br><span class="line">&#125;);</span><br><span class="line"><span class="type">ThreadPoolExecutor</span> <span class="variable">threadPoolExecutor</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ThreadPoolExecutor</span>(<span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, TimeUnit.SECONDS</span><br><span class="line">        , <span class="keyword">new</span> <span class="title class_">ArrayBlockingQueue</span>&lt;&gt;(<span class="number">1000</span>)</span><br><span class="line">        , <span class="keyword">new</span> <span class="title class_">ThreadFactoryBuilder</span>().setUncaughtExceptionHandler(uncaughtExceptionHandler).build());</span><br><span class="line">threadPoolExecutor.execute(() -&gt; &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">RuntimeException</span>(<span class="string">&quot;[catch]线程池中的异常!&quot;</span>);</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ul>
<p>Hold on…..有人的地方就不存在信任这一说- -</p>
<h3 id="兜底方案"><a href="#兜底方案" class="headerlink" title="兜底方案"></a>兜底方案</h3><blockquote>
<p>上面的解决方案是没问题的，但是但是但是，某些开发者可能没有这个意识或者忘记了，导致异常还是被吞噬了</p>
</blockquote>
<p>既然未捕获的异常最终会输出到 <code>System.err</code> 那么重新设置系统的 err 处理，把信息输出到日志系统中。下面这个是兜底方案，会存在部分的不合理，但是为了不丢异常信息还是可以容忍的，日常开发中发现此类异常，需要定位到对应的业务代码，用上面提供的解决方案完善代码；毕竟这只是一个兜底的方案，而不是常规方案</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Stderr</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">Logger</span> <span class="variable">logErr</span> <span class="operator">=</span> LoggerFactory.getLogger(<span class="string">&quot;[UnCatchError]&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">PrintStream</span> <span class="variable">STDERR</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">PrintStream</span>(System.err) &#123;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">println</span><span class="params">(String x)</span> &#123;</span><br><span class="line">            logErr.error(x);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">println</span><span class="params">(Object x)</span> &#123;</span><br><span class="line">            logErr.error(<span class="string">&quot;&quot;</span> + x);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">print</span><span class="params">(<span class="type">boolean</span> b)</span> &#123;</span><br><span class="line">            logErr.error(<span class="string">&quot;&quot;</span> + b);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">print</span><span class="params">(<span class="type">char</span> c)</span> &#123;</span><br><span class="line">            logErr.error(<span class="string">&quot;&quot;</span> + c);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">print</span><span class="params">(<span class="type">int</span> i)</span> &#123;</span><br><span class="line">            logErr.error(<span class="string">&quot;&quot;</span> + i);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">print</span><span class="params">(<span class="type">long</span> l)</span> &#123;</span><br><span class="line">            logErr.error(<span class="string">&quot;&quot;</span> + l);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">print</span><span class="params">(<span class="type">float</span> f)</span> &#123;</span><br><span class="line">            logErr.error(<span class="string">&quot;&quot;</span> + f);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">print</span><span class="params">(<span class="type">double</span> d)</span> &#123;</span><br><span class="line">            logErr.error(<span class="string">&quot;&quot;</span> + d);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">print</span><span class="params">(String s)</span> &#123;</span><br><span class="line">            logErr.error(s);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">static</span> &#123;</span><br><span class="line">        System.setErr(STDERR);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title>JFR</title>
    <url>/2025/02/09/jfr/jfr/posts/undefined/</url>
    <content><![CDATA[<h3 id="学习资料"><a href="#学习资料" class="headerlink" title="学习资料"></a>学习资料</h3><ul>
<li><a href="https://www.zhihu.com/column/c_1264859821121355776">hashcon JFR 全解</a></li>
</ul>
<h3 id="JVM-启动"><a href="#JVM-启动" class="headerlink" title="JVM 启动"></a>JVM 启动</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Java - XX:StartFlightRecording=delay=6s,disk=<span class="literal">true</span>,dumponexit=<span class="literal">true</span>,filename=/Users/wulei/tmp/recording.jfr,maxsize=1024m,maxage=<span class="number">1d</span>,settings=/Users/wulei/IdeaProjects/personal/op-lei4play/op-samples/jfr/lei-<span class="keyword">default</span>.jfc,path-to-gc-roots=<span class="literal">true</span> -XX:FlightRecorderOptions=repository=/Users/wulei/tmp,stackdepth=<span class="number">64</span> test.Main</span><br></pre></td></tr></table></figure>



<p><code>-XX:StartFlightRecording</code>有这个参数就会启用 JFR 记录，以下是相关的参数</p>
<table>
<thead>
<tr>
<th align="center">配置 key</th>
<th align="left">默认值</th>
<th align="left">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="center">delay</td>
<td align="left">0</td>
<td align="left">延迟多久后启动 JFR 记录，支持带单位配置， 例如 delay&#x3D;60s（秒）， delay&#x3D;20m（分钟）， delay&#x3D;1h（小时）， delay&#x3D;1d（天），不带单位就是秒， 0 就是没有延迟直接开始记录。一般为了避免框架初始化等影响，我们会延迟 1 分钟开始记录（例如 Spring cloud 应用，可以看下日志中应用启动耗时，来决定下这个时间</td>
</tr>
<tr>
<td align="center">disk</td>
<td align="left">true</td>
<td align="left">是否写入磁盘，global buffer 满了之后，是直接丢弃还是写入磁盘文件</td>
</tr>
<tr>
<td align="center">dumponexit</td>
<td align="left">false</td>
<td align="left">程序退出时，是否要 dump 出 。jfr 文件</td>
</tr>
<tr>
<td align="center">duration</td>
<td align="left">0</td>
<td align="left">JFR 记录持续时间，同样支持单位配置，不带单位就是秒，0 代表不限制持续时间，一直记录</td>
</tr>
<tr>
<td align="center">filename</td>
<td align="left">启动目录&#x2F;hotspot-pid-26732-id-1-2020_03_12_10_07_22.jfr，pid 后面就是 pid， id 后面是第几个 JFR 记录，可以启动多个 JFR 记录。最后就是时间</td>
<td align="left">dump 的输出文件</td>
</tr>
<tr>
<td align="center">name</td>
<td align="left">无</td>
<td align="left">记录名称，由于可以启动多个 JFR 记录，这个名称用于区分，否则只能看到一个记录 id，不好区分</td>
</tr>
<tr>
<td align="center">maxage</td>
<td align="left">0</td>
<td align="left">这个参数只有在 disk 为 true 的情况下才有效。最大文件记录保存时间，就是 global buffer 满了需要刷入本地临时目录下保存，这些文件最多保留多久的。也可以通过单位配置，没有单位就是秒，默认是 0，就是不限制</td>
</tr>
<tr>
<td align="center">maxsize</td>
<td align="left">250MB</td>
<td align="left">这个参数只有在 disk 为 true 的情况下才有效。最大文件大小，支持单位配置， 不带单位是字节，m 或者 M 代表 MB，g 或者 G 代表 GB。设置为 0 代表不限制大小**。虽然官网说默认就是 0，但是实际用的时候，不设置会有提示**： No limit specified， using maxsize&#x3D;250MB as default。 注意，这个配置不能小于后面将会提到的 maxchunksize 这个参数</td>
</tr>
<tr>
<td align="center">path-to-gc-roots</td>
<td align="left">false</td>
<td align="left">是否记录 GC 根节点到活动对象的路径，一般不打开这个，首先这个在我个人定位问题的时候，很难用到，只要你的编程习惯好。还有就是打开这个，性能损耗比较大，会导致 FullGC 一般是在怀疑有内存泄漏的时候热启动这种采集，并且通过产生对象堆栈无法定位的时候，动态打开即可。一般通过产生这个对象的堆栈就能定位，如果定位不到，怀疑有其他引用，例如 ThreadLocal 没有释放这样的，可以在 dump 的时候采集 gc roots</td>
</tr>
<tr>
<td align="center">settings</td>
<td align="left">default.jfc</td>
<td align="left">位于 <code>$JAVA_HOME/lib/jfr/default.jfc</code>采集 Event 的详细配置，采集的每个 Event 都有自己的详细配置。另一个 JDK 自带的配置是 profile.jfc，位于 <code>$JAVA_HOME/lib/jfr/profile.jfc</code>如果需要指定自己的配置，这里可以设置为全路径的配置文件，类似 <code>settings=/Users/wulei/tmp/lei-default.jfc</code></td>
</tr>
</tbody></table>
<p><strong><code>-XX:FlightRecorderOptions</code></strong> 相关的参数</p>
<table>
<thead>
<tr>
<th align="left">配置 key</th>
<th align="left">默认值</th>
<th align="left">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="left">allow_threadbuffers_to_disk</td>
<td align="left">false</td>
<td align="left">是否允许 在 thread buffer 线程阻塞的时候，直接将 thread buffer 的内容写入文件。默认不启用，一般没必要开启这个参数，只要你设置的参数让 global buffer 大小合理不至于刷盘很慢，就行了</td>
</tr>
<tr>
<td align="left">globalbuffersize</td>
<td align="left">如果不设置，根据设置的 memorysize 自动计算得出</td>
<td align="left">单个 global buffer 的大小，一般通过 memorysize 设置，不建议自己设置</td>
</tr>
<tr>
<td align="left">maxchunksize</td>
<td align="left">12M</td>
<td align="left">存入磁盘的每个临时文件的大小。默认为 12MB，不能小于 1M。可以用单位配置，不带单位是字节，m 或者 M 代表 MB，g 或者 G 代表 GB。注意这个大小最好不要比 memorySize 小，更不能比 globalbuffersize 小，否则会导致性能下降</td>
</tr>
<tr>
<td align="left">memorysize</td>
<td align="left">10M</td>
<td align="left">FR 的 global buffer 占用的整体内存大小，一般通过设置这个参数，numglobalbuffers 还有 globalbuffersize 会被自动计算出。可以用单位配置，不带单位是字节，m 或者 M 代表 MB，g 或者 G 代表 GB</td>
</tr>
<tr>
<td align="left">numglobalbuffers</td>
<td align="left">如果不设置，根据设置的 memorysize 自动计算得出</td>
<td align="left">global buffer 的个数，一般通过 memorysize 设置，不建议自己设置</td>
</tr>
<tr>
<td align="left">old-object-queue-size</td>
<td align="left">256</td>
<td align="left">对于 Profiling 中的 Old Object Sample 事件，记录多少个 Old Object，这个配置并不是越大越好。记录是怎么记录的，会在后面的各种 Event 介绍里面详细介绍。我的建议是，一般应用 256 就够，时间跨度大的，例如 maxage 保存了一周以上的，可以翻倍</td>
</tr>
<tr>
<td align="left">repository</td>
<td align="left">等同于 -Djava.io.tmpdir 指定的目录</td>
<td align="left">JFR 保存到磁盘的临时记录的位置</td>
</tr>
<tr>
<td align="left">retransform</td>
<td align="left">true</td>
<td align="left">是否通过 JVMTI 转换 JFR 相关 Event 类，如果设置为 false，则只在 Event 类加载的时候添加相应的 Java Instrumentation，这个一般不用改，这点内存 metaspace 还是足够的</td>
</tr>
<tr>
<td align="left">samplethreads</td>
<td align="left">true</td>
<td align="left">这个是是否开启线程采集的状态位配置，只有这个配置为 true，并且在 Event 配置中开启线程相关的采集（这个后面会提到），才会采集这些事件</td>
</tr>
<tr>
<td align="left">stackdepth</td>
<td align="left">64</td>
<td align="left">采集事件堆栈深度，有些 Event 会采集堆栈，这个堆栈采集的深度，统一由这个配置指定。注意这个值不能设置过大，如果你采集的 Event 种类很多，堆栈深度大很影响性能。比如你用的是 default.jfc 配置的采集，堆栈深度 64 基本上就是不影响性能的极限了。你可以自定义采集某些事件，增加堆栈深度</td>
</tr>
<tr>
<td align="left">threadbuffersize</td>
<td align="left">8KB</td>
<td align="left">threadBuffer 大小，最好不要修改这个，如果增大，那么随着你的线程数增多，内存占用会增大。过小的话，刷入 global buffer 的次数就会变多。8KB 就是经验中最合适的</td>
</tr>
</tbody></table>
<h3 id="jcmd-命令启动"><a href="#jcmd-命令启动" class="headerlink" title="jcmd 命令启动"></a>jcmd 命令启动</h3><ul>
<li><strong><code>jcmd &lt;pid&gt; JFR.start</code></strong> 启动 JFR 记录，参数和<code>-XX:StartFlightRecording</code>一模一样，请参考上面的表格。但是注意这里不再是逗号分割，而是空格示例，代表启动一个名称为 profile_online， 最多保留一天，最大保留 1G 的本地文件记录</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">jcmd 21 JFR.start name=profile_online maxage=1d maxsize=1g</span><br></pre></td></tr></table></figure>

<ul>
<li><strong><code>jcmd &lt;pid&gt; JFR.stop</code></strong> 停止 JFR 记录，需要传入名称，例如如果要停止上面打开的，则执行：</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">jcmd 21 JFR.stop name=profile_online</span><br></pre></td></tr></table></figure>

<ul>
<li><strong><code>jcmd &lt;pid&gt; JFR.check</code></strong> 查看当前正在执行的 JFR 记录</li>
<li><strong><code>jcmd &lt;pid&gt; JFR.configure</code></strong> 如果不传入参数，则是查看当前配置，传入参数就是修改配置。配置与-XX:FlightRecorderOptions 的一模一样。请参考上面的表格 示例</li>
<li><strong><code>jcmd &lt;pid&gt; JFR.dump</code></strong> 生成 jfr 文件</li>
</ul>
<table>
<thead>
<tr>
<th align="left">参数</th>
<th align="left">默认值</th>
<th align="left">描述</th>
</tr>
</thead>
<tbody><tr>
<td align="left">name</td>
<td align="left">无</td>
<td align="left">指定要查看的 JFR 记录名称</td>
</tr>
<tr>
<td align="left">filename</td>
<td align="left">无</td>
<td align="left">指定文件输出位置</td>
</tr>
<tr>
<td align="left">maxage</td>
<td align="left">0</td>
<td align="left">dump 最多的时间范围的文件，可以通过单位配置，没有单位就是秒，默认是 0，就是不限制</td>
</tr>
<tr>
<td align="left">maxsize</td>
<td align="left">0</td>
<td align="left">dump 最大文件大小，支持单位配置， 不带单位是字节，m 或者 M 代表 MB，g 或者 G 代表 GB。设置为 0 代表不限制大小</td>
</tr>
<tr>
<td align="left">begin</td>
<td align="left">无</td>
<td align="left">dump 开始位置， 可以这么配置：09:00， 21:35:00， 2018-06-03T18:12:56.827Z， 2018-06-03T20:13:46.832， -10m， -3h， or -1d</td>
</tr>
<tr>
<td align="left">end</td>
<td align="left">无</td>
<td align="left">dump 结束位置，可以这么配置： 09:00， 21:35:00， 2018-06-03T18:12:56.827Z， 2018-06-03T20:13:46.832， -10m， -3h， or -1d （STRING， no default value）</td>
</tr>
<tr>
<td align="left">path-to-gc-roots</td>
<td align="left">false</td>
<td align="left">是否记录 GC 根节点到活动对象的路径，一般不记录，dump 的时候打开这个肯定会触发一次 fullGC，对线上应用有影响。最好参考之前对于 JFR 启动记录参数的这个参数的描述，考虑是否有必要</td>
</tr>
</tbody></table>
<h3 id="jfr-配置文件"><a href="#jfr-配置文件" class="headerlink" title="jfr 配置文件"></a>jfr 配置文件</h3><ul>
<li>openJdk 11.0.22</li>
</ul>
<p> <a href="/files/default.jfc">default.jfc</a> </p>
<p> <a href="/files/profile.jfc">profile.jfc</a> </p>
<ul>
<li>优化后的配置文件，基于 openJdk 11.2.22 default.jfr，根据👇🏻JFR Event 中的建议对于某些事件进行了关闭或者调整</li>
</ul>
<p> <a href="/files/lei-default.jfc">lei-default.jfc</a> </p>
<h3 id="JFR-Event"><a href="#JFR-Event" class="headerlink" title="JFR Event"></a>JFR Event</h3><ul>
<li><p><a href="https://zhuanlan.zhihu.com/p/124242959">EVENT-1</a></p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/126709861">EVENT-2</a></p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/158592899">EVENT-3</a></p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/158592899">JIT相关jfr事件</a></p>
</li>
</ul>
<p><img data-src="/images/jfr_01_01.png" alt="img"></p>
]]></content>
      <categories>
        <category>JFR</category>
      </categories>
      <tags>
        <tag>JVM</tag>
        <tag>JFR</tag>
        <tag>监控</tag>
      </tags>
  </entry>
  <entry>
    <title>JVM内存相关的监控指标</title>
    <url>/2025/02/09/jvm/jvm-nei-cun-xiang-guan-de-jian-kong-zhi-biao/posts/undefined/</url>
    <content><![CDATA[<p><img data-src="/images/jvm-memory.PNG" alt="jvm内存图片"></p>
<h3 id="Heap"><a href="#Heap" class="headerlink" title="Heap"></a>Heap</h3><blockquote>
<p>JVM Heap代表存放Java Objects的Heap</p>
</blockquote>
<h3 id="Non-Heap"><a href="#Non-Heap" class="headerlink" title="Non-Heap"></a>Non-Heap</h3><h4 id="1-SpringBoot的JVM-metrics埋点代码"><a href="#1-SpringBoot的JVM-metrics埋点代码" class="headerlink" title="1. SpringBoot的JVM metrics埋点代码"></a>1. SpringBoot的JVM metrics埋点代码</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 通过io.micrometer.core引入了JVMMemoryuMetrics这个埋点实现</span></span><br><span class="line"><span class="keyword">for</span> (MemoryPoolMXBean memoryPoolBean : ManagementFactory.getPlatformMXBeans(MemoryPoolMXBean.class)) &#123;</span><br><span class="line">    <span class="type">String</span> <span class="variable">area</span> <span class="operator">=</span> MemoryType.HEAP.equals(memoryPoolBean.getType()) ? <span class="string">&quot;heap&quot;</span> : <span class="string">&quot;nonheap&quot;</span>;</span><br><span class="line">    Iterable&lt;Tag&gt; tagsWithId = Tags.concat(tags, <span class="string">&quot;id&quot;</span>, memoryPoolBean.getName(), <span class="string">&quot;area&quot;</span>, area);</span><br><span class="line"></span><br><span class="line">    Gauge.builder(<span class="string">&quot;jvm.memory.used&quot;</span>, memoryPoolBean, (mem) -&gt; getUsageValue(mem, MemoryUsage::getUsed))</span><br><span class="line">        .tags(tagsWithId)</span><br><span class="line">        .description(<span class="string">&quot;The amount of used memory&quot;</span>)</span><br><span class="line">        .baseUnit(BaseUnits.BYTES)</span><br><span class="line">        .register(registry);</span><br><span class="line"></span><br><span class="line">    Gauge</span><br><span class="line">        .builder(<span class="string">&quot;jvm.memory.committed&quot;</span>, memoryPoolBean, (mem) -&gt; getUsageValue(mem, MemoryUsage::getCommitted))</span><br><span class="line">        .tags(tagsWithId)</span><br><span class="line">        .description(<span class="string">&quot;The amount of memory in bytes that is committed for the Java virtual machine to use&quot;</span>)</span><br><span class="line">        .baseUnit(BaseUnits.BYTES)</span><br><span class="line">        .register(registry);</span><br><span class="line"></span><br><span class="line">    Gauge.builder(<span class="string">&quot;jvm.memory.max&quot;</span>, memoryPoolBean, (mem) -&gt; getUsageValue(mem, MemoryUsage::getMax))</span><br><span class="line">        .tags(tagsWithId)</span><br><span class="line">        .description(<span class="string">&quot;The maximum amount of memory in bytes that can be used for memory management&quot;</span>)</span><br><span class="line">        .baseUnit(BaseUnits.BYTES)</span><br><span class="line">        .register(registry);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// MemoryPoolMXBean接口的实现类是sun.management.MemoryPoolImpl，该类通过native method得到JVM提供的内存使用信息</span></span><br><span class="line"><span class="comment">// Native VM support</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">native</span> MemoryUsage <span class="title function_">getUsage0</span><span class="params">()</span>;</span><br></pre></td></tr></table></figure>

<h4 id="2-JVM本身的代码"><a href="#2-JVM本身的代码" class="headerlink" title="2. JVM本身的代码"></a>2. JVM本身的代码</h4><blockquote>
<p>设置-XX:NativeMemoryTracking&#x3D;summary或者details，然后使用jcmd去查看</p>
</blockquote>
<ul>
<li>CodeCache</li>
<li>Metaspace</li>
<li>CompressedClassSpace</li>
<li>DirectBuffer</li>
<li>Thread Stacks</li>
</ul>
<h3 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h3><h4 id="1-JVM里used内存很低，但是容器物理内存占用很高"><a href="#1-JVM里used内存很低，但是容器物理内存占用很高" class="headerlink" title="1. JVM里used内存很低，但是容器物理内存占用很高"></a>1. JVM里used内存很低，但是容器物理内存占用很高</h4><p>因为k8s不允许使用交换分区，所以这里不用考虑外存和内存的交换关系。</p>
<p>JVM申请内存的时候，会预先使用<strong>pretouch</strong>的方式声明去告知OS，期望使用多少size的内存，由于物理内存的分配（内核本身的虚拟内存-物理内存管理）时惰性的，所以声明要使用多少size，不代表物理内存就立刻分配多少。</p>
<p>比如JavaHeap声明了1G的内存需要使用，但实际使用过程中，物理内存也是逐步被分配的，由于JavaHeap的内存被JVM的GC管理，当Heap满时，JVM的GC会内部释放内存空间，很明显，GC的过程不会让OS感知，不会去释放物理内存，假如FGC后，JavaHeap实际used的内存（常驻在JavaHeap）中只有200M，但此时容器物理内存很可能是1G多。</p>
]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
        <tag>监控</tag>
        <tag>内存</tag>
      </tags>
  </entry>
  <entry>
    <title>JVM重要参数</title>
    <url>/2025/02/09/jvm/jvm-chong-yao-can-shu/posts/undefined/</url>
    <content><![CDATA[<h2 id="常规启动配置参数"><a href="#常规启动配置参数" class="headerlink" title="常规启动配置参数"></a>常规启动配置参数</h2><table>
<thead>
<tr>
<th align="left">参数</th>
<th align="left">说明</th>
<th align="left">备注</th>
</tr>
</thead>
<tbody><tr>
<td align="left">-XX:+PrintFlagsFinal</td>
<td align="left">启动时打印出所有JVM参数</td>
<td align="left"></td>
</tr>
<tr>
<td align="left">-XX:+HeapDumpOnOutOfMemoryError-XX:HeapDumpPath&#x3D;&#x2F;path&#x2F;to&#x2F;heap.hprof-XX:+ExitOnOutOfMemoryError</td>
<td align="left">开启OOM时堆转储指定dump文件位置发生 OOM 时强制 JVM 立即退出</td>
<td align="left">！！dump hprof文件时要求内存比较大，这块后续要再找更好的方案</td>
</tr>
<tr>
<td align="left">-Xlog:gc*:file&#x3D;gc.log::filecount&#x3D;5,filesize&#x3D;20M</td>
<td align="left">JDK 9+ 的新版 GC 日志参数-Xlog:  gc*                    # 记录所有gc相关日志  :file&#x3D;gc.log          # 输出到gc.log文件  :                           # 空的tag过滤器  :filecount&#x3D;5,         # 最多保留5个文件  filesize&#x3D;20M          # 每个文件最大20MB</td>
<td align="left">等价  jdk8           -verbose:gc        -Xloggc:&#x2F;path&#x2F;to&#x2F;gc.log        -XX:+PrintGCDetails        -XX:+PrintGCDateStamps        -XX:+PrintGCTimeStamps        -XX:+UseGCLogFileRotation        -XX:NumberOfGCLogFiles&#x3D;5        -XX:GCLogFileSize&#x3D;20M</td>
</tr>
<tr>
<td align="left">-XX:StartFlightRecording&#x3D;delay&#x3D;1s,disk&#x3D;true,dumponexit&#x3D;true,filename&#x3D;.&#x2F;logs&#x2F;recording.jfr,maxsize&#x3D;1024m,maxage&#x3D;1d,path-to-gc-roots&#x3D;true-XX:FlightRecorderOptions&#x3D;stackdepth&#x3D;128</td>
<td align="left">jfr启动参数，具体参考 <a href="https://rq3nt70g815.feishu.cn/wiki/CtdmwY0yPiUkgKkXidecur63nVc">JFR</a></td>
<td align="left"></td>
</tr>
<tr>
<td align="left">-Xlog:safepoint&#x3D;debug:file&#x3D;.&#x2F;logs&#x2F;safepoint.log:utctime,level,tags:filecount&#x3D;50,filesize&#x3D;100M</td>
<td align="left">safepoint</td>
<td align="left"></td>
</tr>
</tbody></table>
<p><img data-src="data:image/jpeg;base64,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" alt="123"></p>
]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
        <tag>参数</tag>
      </tags>
  </entry>
  <entry>
    <title>Netty Reactor 启动流程-1</title>
    <url>/2025/02/09/netty/1.netty-reactor-qi-dong-liu-cheng/posts/undefined/</url>
    <content><![CDATA[<h2 id="相关链接"><a href="#相关链接" class="headerlink" title="相关链接"></a>相关链接</h2><p><a href="https://zhuanlan.zhihu.com/p/459313682">详细图解Netty Reactor启动全流程 | 万字长文 | 多图预警</a></p>
<p><img data-src="/images/netty_01_01.png" alt="netty"></p>
<h2 id="Netty-服务端的启动流程"><a href="#Netty-服务端的启动流程" class="headerlink" title="Netty 服务端的启动流程"></a>Netty 服务端的启动流程</h2><ul>
<li>创建服务端<code>NioServerSocketChannel</code>并初始化</li>
<li>将服务端<code>NioServerSocketChannel</code>注册到<code>主Reactor线程组</code>中</li>
<li>注册成功后，开始初始化<code>NioServerSocketChannel</code>中的 pipeline，然后在 pipeline 中触发 channelRegister 事件。</li>
<li>随后由<code>NioServerSocketChannel</code>绑定端口地址。</li>
<li>绑定端口地址成功后，向<code>NioServerSocketChannel</code>对应的<code>Pipeline</code>中触发传播<code>ChannelActive事件</code>，在<code>ChannelActive事件回调</code>中向<code>Main Reactor</code>注册<code>OP_ACCEPT事件</code>，开始等待客户端连接。服务端启动完成。</li>
</ul>
<p><img data-src="/images/netty_01_02.png" alt="netty"></p>
<h2 id="1-initAndRegister"><a href="#1-initAndRegister" class="headerlink" title="1. initAndRegister"></a>1. initAndRegister</h2><p><img data-src="/images/netty_01_03.png" alt="netty"></p>
<p>开始注册</p>
<p><img data-src="/images/netty_01_04.png" alt="netty"></p>
<h2 id="2-Bind"><a href="#2-Bind" class="headerlink" title="2. Bind"></a>2. Bind</h2><p><code>bind事件</code>在 Netty 中被定义为<code>outbound事件</code>，所以它在<code>pipeline</code>中是反向传播。先从<code>TailContext</code>开始反向传播直到<code>HeadContext</code>；<code>bind</code>的核心逻辑也正是实现在<code>HeadContext</code>中</p>
<blockquote>
<p>headContext 中的绑定方法</p>
</blockquote>
<p><img data-src="/images/netty_01_05.png" alt="netty"></p>
<blockquote>
<p>NioServerSocketChannel 中的绑定动作</p>
</blockquote>
<p><img data-src="/images/netty_01_06.png" alt="netty"></p>
<blockquote>
<p>绑定完成后触发 active 操作 –&gt; HeadContext</p>
</blockquote>
<p><img data-src="/images/netty_01_07.png" alt="netty"></p>
<blockquote>
<p>io.netty.channel.AbstractChannel.AbstractUnsafe#beginRead</p>
</blockquote>
<p><img data-src="/images/netty_01_08.png" alt="netty"></p>
<blockquote>
<p>io.netty.channel.nio.AbstractNioChannel#doBeginRead</p>
</blockquote>
<p><img data-src="/images/netty_01_09.png" alt="netty"></p>
<h2 id="细节点"><a href="#细节点" class="headerlink" title="细节点"></a>细节点</h2><h3 id="Reactor线程的启动是在向Reactor提交第一个异步任务的时候启动的"><a href="#Reactor线程的启动是在向Reactor提交第一个异步任务的时候启动的" class="headerlink" title="Reactor线程的启动是在向Reactor提交第一个异步任务的时候启动的"></a><code>Reactor线程</code>的启动是在向<code>Reactor</code>提交第一个异步任务的时候启动的</h3><blockquote>
<p>io.netty.util.concurrent.SingleThreadEventExecutor#execute(java.lang.Runnable, boolean)</p>
</blockquote>
<p><img data-src="/images/netty_01_10.png" alt="netty"></p>
<h3 id="Reactor线程的核心工作-轮询所有注册其上的Channel中的IO就绪事件，处理对应Channel上的IO事件，执行异步任务"><a href="#Reactor线程的核心工作-轮询所有注册其上的Channel中的IO就绪事件，处理对应Channel上的IO事件，执行异步任务" class="headerlink" title="Reactor线程的核心工作 轮询所有注册其上的Channel中的IO就绪事件，处理对应Channel上的IO事件，执行异步任务"></a><code>Reactor</code>线程的核心工作 <code>轮询所有注册其上的Channel中的IO就绪事件</code>，<code>处理对应Channel上的IO事件</code>，<code>执行异步任务</code></h3><blockquote>
<p>io.netty.channel.nio.NioEventLoop#run</p>
</blockquote>
<p><img data-src="/images/netty_01_11.png" alt="netty"></p>
<h3 id="Channel-的各种事件触发顺序"><a href="#Channel-的各种事件触发顺序" class="headerlink" title="Channel 的各种事件触发顺序"></a>Channel 的各种事件触发顺序</h3><ol>
<li><p>handlerAdded</p>
<p> socket 向 jdk selector 注册后、在通知注册的 promise 完成之前（也就是 promise 回调之前）触发</p>
<p> <img data-src="/images/netty_01_12.png" alt="netty"></p>
</li>
<li><p>channelRegistered</p>
<p> 在通知 promise 完成后（也就是回调执行完成之后）会传播 Registered 事件</p>
<p> <img data-src="/images/netty_01_13.png" alt="netty"></p>
</li>
<li><p>Active </p>
<p>a. 服务端 NioServerSocketChannel 判断是否激活的标准为端口是否绑定成功。</p>
<p>b. </p>
   <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">NioServerSocketChannel</span> <span class="keyword">extends</span> <span class="title class_">AbstractNioMessageChannel</span></span><br><span class="line">                             <span class="keyword">implements</span> <span class="title class_">io</span>.netty.channel.socket.ServerSocketChannel &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">isActive</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> isOpen() &amp;&amp; javaChannel().socket().isBound();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>c. 客户端<code>NioSocketChannel</code>判断是否激活的标准为是否处于<code>Connected状态</code>。</p>
<p>d. </p>
   <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">isActive</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="type">SocketChannel</span> <span class="variable">ch</span> <span class="operator">=</span> javaChannel();</span><br><span class="line">    <span class="keyword">return</span> ch.isOpen() &amp;&amp; ch.isConnected();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p> e. 向后传播 active 事件<br> f. <code>readIfIsAutoRead</code></p>
<blockquote>
<p>如果开启了自动读（io.netty.channel.ChannelConfig#isAutoRead），则注册对应感兴趣的事件</p>
</blockquote>
<ul>
<li>server 连接注册 OP_ACCEPT 事件</li>
<li>client 连接注册 OP_READ 事件</li>
</ul>
</li>
</ol>
<h3 id="向底层-selector-注册"><a href="#向底层-selector-注册" class="headerlink" title="向底层 selector 注册"></a>向底层 selector 注册</h3><blockquote>
<p>io.netty.channel.nio.AbstractNioChannel#doRegister</p>
</blockquote>
<p><img data-src="/images/netty_01_14.png" alt="netty"></p>
<h3 id="NioServerSocketChannel-注册成功后回调任务进行端口绑定，会将端口绑定封装为一个任务提交到队列中，而不是即刻执行"><a href="#NioServerSocketChannel-注册成功后回调任务进行端口绑定，会将端口绑定封装为一个任务提交到队列中，而不是即刻执行" class="headerlink" title="NioServerSocketChannel 注册成功后回调任务进行端口绑定，会将端口绑定封装为一个任务提交到队列中，而不是即刻执行"></a>NioServerSocketChannel 注册成功后回调任务进行端口绑定，会将端口绑定封装为一个任务提交到队列中，而不是即刻执行</h3><p><img data-src="/images/netty_01_15.png" alt="netty"></p>
<h3 id="事件在pipeline中的传播"><a href="#事件在pipeline中的传播" class="headerlink" title="事件在pipeline中的传播"></a>事件在<code>pipeline</code>中的传播</h3><ul>
<li><code>inbound事件</code>从<code>HeadContext</code>开始逐个向后传播直到<code>TailContext</code></li>
<li><code>outbound事件</code>则是反向传播，从<code>TailContext</code>开始反向向前传播直到<code>HeadContext</code></li>
</ul>
<p><img data-src="/images/netty_01_16.png" alt="netty"></p>
<h3 id="服务端-Socket-和客户端-Socket-分别在何时向-seletor-注册感兴趣的事件？"><a href="#服务端-Socket-和客户端-Socket-分别在何时向-seletor-注册感兴趣的事件？" class="headerlink" title="服务端 Socket 和客户端 Socket 分别在何时向 seletor 注册感兴趣的事件？"></a>服务端 Socket 和客户端 Socket 分别在何时向 seletor 注册感兴趣的事件？</h3><ul>
<li>注册感兴趣的事件触发时机都是<code>ChannelActive</code><ul>
<li><img data-src="/images/netty_01_17.png" alt="netty"></li>
<li>对于服务端 socket 来说，bind 成功后会传递 <code>channelActive</code>事件</li>
<li>io.netty.channel.AbstractChannel.AbstractUnsafe#bind</li>
<li><img data-src="/images/netty_01_18.png" alt="netty"></li>
<li>对于客户端 socket 来说，register 成功后会传递 <code>channelActive</code>事件</li>
<li>io.netty.channel.AbstractChannel.AbstractUnsafe#register0</li>
<li><img data-src="/images/netty_01_19.png" alt="netty"></li>
</ul>
</li>
<li>通过 <code>HeadContext#read</code> 方法进行感兴趣事件的注册</li>
</ul>
<blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">io.netty.channel.AbstractChannel.AbstractUnsafe#beginRead</span><br></pre></td></tr></table></figure></blockquote>
<p><img data-src="/images/netty_01_20.png" alt="netty"></p>
<blockquote>
<p>io.netty.channel.nio.AbstractNioChannel#doBeginRead</p>
</blockquote>
<p><img data-src="/images/netty_01_21.png" alt="netty"></p>
]]></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>Netty</tag>
        <tag>源码解析</tag>
      </tags>
  </entry>
  <entry>
    <title>Spring Cloud Gateway</title>
    <url>/2025/02/09/wang-guan/spring-cloud-gateway/posts/undefined/</url>
    <content><![CDATA[<h2 id="重要属性"><a href="#重要属性" class="headerlink" title="重要属性"></a>重要属性</h2><ol>
<li>GATEWAY_ORIGINAL_REQUEST_URL_ATTR</li>
</ol>
<ul>
<li>记录原始的url请求</li>
<li>错误重试时可以用原始URI重试</li>
<li>可以记录完整的请求转换链路</li>
<li>故障分析时可以知道请求的来源</li>
<li>在路由重写时需要更新此属性</li>
</ul>
<ol start="2">
<li>GATEWAY_REQUEST_URL_ATTR</li>
</ol>
<ul>
<li>存储请求将要转发的目标URL</li>
<li>后续的过滤器和路由可以通过这个属性知道请求要被转发到哪里</li>
<li>在路由重写时需要更新此属性</li>
</ul>
<ol start="3">
<li>PRESERVE_HOST_HEADER_ATTRIBUTE</li>
</ol>
<ul>
<li>控制是否保留原始请求的 Host 头</li>
<li>true: 转发请求时会保留客户端的原始 Host header</li>
<li>false: 会使用目标服务的 Host</li>
<li>使用场景：假设自定义的过滤器修改了host属性，如果没有开启此配置，那么后续的处理可能影响此属性，这时候需要开启此配置</li>
</ul>
<h2 id="重要过滤器"><a href="#重要过滤器" class="headerlink" title="重要过滤器"></a>重要过滤器</h2><ol>
<li><p>RetryGatewayFilterFactory</p>
<blockquote>
<p>重试过滤器</p>
</blockquote>
 <figure class="highlight java"><table><tr><td class="code"><pre><span class="line">- name: Retry #重试策略:目前只对提供者下线导致的连接异常重试，需持续观察异常情况</span><br><span class="line">  args: </span><br><span class="line">    retries: <span class="number">1</span></span><br><span class="line">    series: #不对http状态来判断是否进行重试</span><br><span class="line">    exceptions: io.netty.channel.AbstractChannel$AnnotatedConnectException</span><br></pre></td></tr></table></figure></li>
</ol>
]]></content>
      <categories>
        <category>网关</category>
      </categories>
      <tags>
        <tag>网关</tag>
        <tag>spring cloud gateway</tag>
        <tag>spring cloud</tag>
      </tags>
  </entry>
  <entry>
    <title>Socket</title>
    <url>/2025/02/09/wang-luo/socket/posts/undefined/</url>
    <content><![CDATA[<ul>
<li><a href="https://zhuanlan.zhihu.com/p/455352339">聊聊Netty那些事儿之从内核角度看IO模型</a></li>
</ul>
<h3 id="Socket-数据接收到-Epoll-处理流程"><a href="#Socket-数据接收到-Epoll-处理流程" class="headerlink" title="Socket 数据接收到 Epoll 处理流程"></a>Socket 数据接收到 Epoll 处理流程</h3><pre>
<code class="mermaid">

sequenceDiagram
    participant S as Socket
    participant WQ as Wait Queue
    participant CB as Callback (ep_poll_callback)
    participant EP as eppoll_entry
    participant EI as epitem
    participant EPL as eventpoll

    S-&gt;&gt;S: 接收数据
    S-&gt;&gt;WQ: 触发等待队列
    WQ-&gt;&gt;CB: 调用回调函数
    CB-&gt;&gt;EP: container_of 找到 eppoll_entry
    EP-&gt;&gt;EI: 访问 base 指针找到 epitem
    EI-&gt;&gt;EPL: 将 epitem 加入活跃队列
</code>
</pre>


<ol>
<li><p>数据到达和初始处理： </p>
<ul>
<li>网卡接收数据，通过 DMA 将数据放入 Ring Buffer。</li>
<li>触发软中断，内核将数据包（sk_buff）放入 socket 的接收队列。</li>
</ul>
</li>
<li><p>Socket 唤醒等待队列： </p>
<ul>
<li>Socket 检测到有新数据，开始唤醒其等待队列（wait_queue）中的等待者。</li>
<li>获取其中一个 wait_queue_entry_t，这里不获取全部一是避免惊群效应，二是 epoll 场景下一般也只会有一个 wait_queue_entry_t</li>
</ul>
</li>
<li><p>回调函数触发： </p>
<ul>
<li>对于 epoll 添加的等待项，其 wait_queue_entry_t 的回调函数是 ep_poll_callback。</li>
<li>内核调用这个回调函数，传入 wait_queue_entry_t 指针作为参数。</li>
</ul>
</li>
<li><p>找到 eppoll_entry： </p>
<ul>
<li>在 ep_poll_callback 函数中，使用 container_of 宏。</li>
<li>通过 wait_queue_entry_t 指针，找到包含它的 eppoll_entry 结构。</li>
</ul>
 <figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">eppoll_entry</span> *<span class="title">pwq</span> =</span> container_of(wait, <span class="keyword">struct</span> eppoll_entry, wait);</span><br></pre></td></tr></table></figure>
</li>
<li><p>从 eppoll_entry 到 epitem： </p>
<ul>
<li>eppoll_entry 结构中有一个 base 指针，直接指向关联的 epitem。</li>
</ul>
 <figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">epitem</span> *<span class="title">epi</span> =</span> pwq-&gt;base;</span><br></pre></td></tr></table></figure>
</li>
<li><p>获取 eventpoll 结构： </p>
<ul>
<li>epitem 结构中包含指向其关联的 eventpoll 结构的指针。</li>
</ul>
 <figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">eventpoll</span> *<span class="title">ep</span> =</span> epi-&gt;ep;</span><br></pre></td></tr></table></figure>
</li>
<li><p>将 epitem 加入活跃队列： </p>
<ul>
<li>检查 epitem 是否已经在活跃队列中。</li>
<li>如果不在，则将其添加到 eventpoll 的活跃队列（rdllist）中。</li>
</ul>
 <figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (!ep_is_linked(&amp;epi-&gt;rdllink))</span><br><span class="line">    list_add_tail(&amp;epi-&gt;rdllink, &amp;ep-&gt;rdllist);</span><br></pre></td></tr></table></figure>
</li>
<li><p>唤醒等待的进程： </p>
<ul>
<li>如果有进程正在等待 epoll 事件（通过 epoll_wait），唤醒它。</li>
</ul>
</li>
</ol>
]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>网络</tag>
        <tag>socket</tag>
      </tags>
  </entry>
  <entry>
    <title>TCP 连接</title>
    <url>/2025/02/09/wang-luo/tcp-lian-jie/posts/undefined/</url>
    <content><![CDATA[<h3 id="TCP-状态转换图"><a href="#TCP-状态转换图" class="headerlink" title="TCP 状态转换图"></a>TCP 状态转换图</h3><p><img data-src="/images/tcp_01_01.png" alt="img"></p>
<h3 id="TCP-连接的分组交换"><a href="#TCP-连接的分组交换" class="headerlink" title="TCP 连接的分组交换"></a>TCP 连接的分组交换</h3><p><img data-src="/images/tcp_01_02.png" alt="img"></p>
<ul>
<li>MSS（Maximum Segment Size）: 指定了 TCP 数据包中数据部分的最大长度<ul>
<li>一般约定最小是 536，因为 IPv4 规范中建议的最小 MTU 是 576，减去 20 字节的标准 IPv4 头的长度，再减去 20 字节的标准 TCP 头的长度，得到 536 字节</li>
<li>一般约定最大是 1460，因为 IPv4 规范中建议的最大 MTU 是 1500</li>
</ul>
</li>
<li>MSS 以双方约定的最小值为准</li>
<li>请求 ACK 是服务端对客户端发送过来的数据包的响应</li>
<li>应答 ACK 是客户端对服务端发送过来的数据包的响应</li>
<li>TIME_WAIT 状态<ul>
<li>主动关闭的那端经历了这个状态</li>
<li>此状态的持续时间最长是 2MSL，MSL 在 RFC 1122 的建议值是 2 分钟，在 Berkeley 修改为 30s，意味着 TIME_WAIT 状态的持续时间在 1 分钟到 4 分钟之间<ul>
<li>MSL 是任何 IP 数据报能存活的最长时间，因为每个数据报都有跳限（hop limit），最大是 255 跳</li>
</ul>
</li>
<li>此状态存在的理由<ul>
<li>可靠的实现 TCP 全双工连接的终止</li>
<li>被动终止的一方会发送最终的 FIN，因此此端必须维护状态信息，以允许此端重新发送最终的 ACK。如果此端不维护状态信息了，那么会响应一个 <strong>RST</strong>，会被对端解释为一个错误</li>
<li>允许老的重复分节在网络中消逝</li>
<li>假设某个连接关闭了，然后在相同的客户端、服务器之间建立的一个新的连接，这个连接的四元组与之前关闭的连接完全一致，后一个连接称为前一个连接的化身。TCP 必须防止来自某个连接的老的重复分组在该连接已终止后再现，从而被误解成属于同一个连接的某个新的化身。为了做到这一点，TCP 将不给处于 TIME_WAIT 状态的连接发起新的化身。又因为 TIME_WAIT 最长存活时间为 2MSL，此时间足够旧连接的数据包消逝了</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="Listen"><a href="#Listen" class="headerlink" title="Listen"></a>Listen</h3><blockquote>
<p>最主要的工作就是<code>申请和初始化</code>接收队列，包括<code>全连接队列以及半连接队列</code></p>
</blockquote>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// fd、backlog</span></span><br><span class="line">listen(fd, <span class="number">128</span>)</span><br></pre></td></tr></table></figure>

<h4 id="全连接队列"><a href="#全连接队列" class="headerlink" title="全连接队列"></a>全连接队列</h4><blockquote>
<p>全连接队列是一个链表，内核中使用链表的 head、tail，方便应用层直接根据头尾指针查找接入的连接</p>
</blockquote>
<h5 id="全连接队列的长度"><a href="#全连接队列的长度" class="headerlink" title="全连接队列的长度"></a>全连接队列的长度</h5><ul>
<li>最大长度是 listen 传入的 backlog 和 net.core.somaxconn 之间较小的值。如果需要加大长度，需要调整这两个值。</li>
<li>使用 <code>cat /proc/sys/net/core/somaxconn</code> 命令查看</li>
<li>查看某个进程的全连接队列的长度，通过使用命令 **<code>ss -nlt</code>**进行查看，其中 <strong>Send-Q</strong> 表示全连接队列长度</li>
</ul>
<p><img data-src="/images/tcp_01_03.png" alt="img"></p>
<h5 id="判断全连接队列是否溢出"><a href="#判断全连接队列是否溢出" class="headerlink" title="判断全连接队列是否溢出"></a>判断全连接队列是否溢出</h5><p><strong><code>watch &#39;netstat -s | grep overflowed&#39;</code></strong></p>
<p>如果上述命令结果显示 <strong>xx times the listen queue of a socket overflowed</strong> 则说明有全连接队列溢出了</p>
<h5 id="半连接队列的长度"><a href="#半连接队列的长度" class="headerlink" title="半连接队列的长度"></a>半连接队列的长度</h5><ul>
<li>半连接队列的长度是 <em><strong>min（backlog，somaxconn，tcp_max_syn_backlog） + 1</strong></em> 再向上去整到 <strong>2</strong> 的 <em><strong>N</strong></em> 次幂，但最小不能小于 <strong>16</strong></li>
<li><code>cat /proc/sys/net/ipv4/tcp_max_syn_backlog</code> 命令查看 tcp_max_syn_backlog</li>
<li>假设某内核参数 net.core.somaxconn&#x3D;128，net.ipv4.tcp_max_syn_backlog&#x3D;8192，用户 backlog&#x3D;5，经过以下步骤计算得出为 16<ul>
<li>min(backlog, somaxconn) &#x3D; min(5, 128) &#x3D; 5</li>
<li>min(5, tcp_max_syn_backlog) &#x3D; min(5, 8192) &#x3D; 5</li>
<li>max（5， 8） &#x3D; 8  这一步是内核为了避免传入一个太小的值导致无法接收连接，所以必须要&gt;&#x3D;8</li>
<li>roundup_pow_of_two(8 + 1) &#x3D; 16</li>
</ul>
</li>
<li>假设某内核参数 net.core.somaxconn&#x3D;128，net.ipv4.tcp_max_syn_backlog&#x3D;8192，用户 backlog&#x3D;512，经过以下步骤计算得出为 256<ul>
<li>min(backlog, somaxconn) &#x3D; min(512, 128) &#x3D; 128</li>
<li>min(128, tcp_max_syn_backlog) &#x3D; min(128, 8192) &#x3D; 128</li>
<li>max(128, 8) &#x3D; 128  </li>
<li>roundup_pow_of_two(128 + 1) &#x3D; 256</li>
</ul>
</li>
</ul>
<h5 id="判断半连接队列是否溢出？"><a href="#判断半连接队列是否溢出？" class="headerlink" title="判断半连接队列是否溢出？"></a>判断半连接队列是否溢出？</h5><ol>
<li>计算办连接队列的长度</li>
<li>查看当前SYN_RECV状态的连接数量</li>
</ol>
<p><strong><code>netstat -antp | grep SYN_RECV | wc -l</code></strong></p>
<p>其实只需要保证 <strong><code>tcp_syncookies</code></strong> 这个内核参数是 <strong>1</strong> 就不会有半连接队列溢出的问题，👍🏻推荐开启此参数！！且开启此参数可以抵御 SYN flood 攻击</p>
<p><strong><code>cat /proc/sys/net/ipv4/tcp_syncookies</code></strong> 通过此命令查看对应参数</p>
<p><strong><code>echo 1 &gt; /proc/sys/net/ipv4/tcp_syncookies</code></strong> 此命令进行修改</p>
<h3 id="Connect"><a href="#Connect" class="headerlink" title="Connect"></a>Connect</h3><p>客户端在执行 connect 函数的时候，把本地 socket 状态设置成了**<code>TCP_SYN_SENT</code>**，选了一个可用端口，接着发出 SYN 握手请求并启动重传定时器</p>
<h4 id="选择可用端口"><a href="#选择可用端口" class="headerlink" title="选择可用端口"></a>选择可用端口</h4><ol>
<li>如果调用过 bind，那么以 bind 定义的端口为准，否则需要按照以下规则寻找可用的端口</li>
<li>可用的端口范围是根据内核参数 <strong><code>net.ipv4.ip_local_port_range</code></strong>，此参数的范围就是能选择的端口范围，可以使用命令 **<code>cat /proc/sys/net/ipv4/ip_local_port_range</code>**进行查看，下图表示能使用的范围是 32768-60999。注意这里查找端口是循环的，如果需要很多轮才查找到可用的端口，会导致 connect 系统调用的 cpu 升高<ul>
<li><img data-src="/images/tcp_01_04.png" alt="img"></li>
</ul>
</li>
<li>判断选择的端口是否在保留端口中，如果是则不能使用此端口。内核参数**<code>net.ipv4.ip_local_reserved_ports</code>** 表示保留端口，如果希望某些端口不被内核使用，将他们写到这个参数里面就可以。<strong><code>cat /proc/sys/net/ipv4/ip_local_reserved_ports</code></strong></li>
<li>判断选择的端口是否已经使用过了，内核会维护一个使用过的端口的 hash 表，如果在 hash 表中没有找到，证明此端口是可用的，后面会在此 hash 表中记录端口已经被使用</li>
<li>如果上面还是没有找到合适的端口，就会出现 <strong>Cannot assign requested address</strong> 这个错误</li>
</ol>
<h4 id="端口被使用过怎么办？"><a href="#端口被使用过怎么办？" class="headerlink" title="端口被使用过怎么办？"></a>端口被使用过怎么办？</h4><blockquote>
<p>👆🏻选择可用端口的第四步判断端口是否已经使用过了，不是简单的判断端口是否使用过了，而是如果端口被使用过了，且<strong>四元组完全一致</strong>时才无法使用此端口，如果四元组有一个不一致，那么这个端口是可以使用的。</p>
</blockquote>
<h4 id="发起-sync-请求"><a href="#发起-sync-请求" class="headerlink" title="发起 sync 请求"></a>发起 sync 请求</h4><ol>
<li>申请一个 skb，并将其设置为<code>SYN</code>包</li>
<li>添加到发送队列 <code>sk_write_queue</code> </li>
<li>调用<code>tcp_transmit_skb</code>将该包发出</li>
<li>启动一个重传定时器，超时会重发。首次超时时间是在<code>TCP_TIMEOUT_INIT</code>宏中定义的</li>
</ol>
<h3 id="三次握手"><a href="#三次握手" class="headerlink" title="三次握手"></a>三次握手</h3><p><img data-src="/images/tcp_01_05.png" alt="img"></p>
<ol>
<li>第一次握手服务端只是创建了**<code>request sock</code>**，并加入到半连接队列中，并没有创建 socket，实际创建socket是在三次握手完成时。</li>
<li>TCP 连接建立的网络耗时大约需要三次传输，再加上少许的双方 cpu 开销，总共大约比 <strong>1.5 倍 RTT</strong> 大一点点。不过从客户端角度来看，只要 ACK 包发出了，内核就认为连接建立成功可以开始发送数据了，所以如果在客户端进行打点统计 TCP 连接建立耗时只需要两次传输耗时——即一个 RTT 多一点的时间（服务端也是同理，从 SYN 包接收到开始算起，到 ACK 包接收完毕）</li>
</ol>
]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>网络</tag>
        <tag>tcp</tag>
      </tags>
  </entry>
  <entry>
    <title>linux内核发送网络包</title>
    <url>/2025/02/09/wang-luo/linux-nei-he-fa-song-wang-luo-bao/posts/undefined/</url>
    <content><![CDATA[<h3 id="网络发送过程汇总"><a href="#网络发送过程汇总" class="headerlink" title="网络发送过程汇总"></a>网络发送过程汇总</h3><p><img data-src="/images/socket_02_10.png" alt="img"></p>
<ul>
<li>上图中网络设备子系统在发送网络包的时候，是通过while循环不断地从队列中取出skb并进行发送。这时候其实都是占用的用户进程的系统态时间(sy)，只有当<code>quota</code> 用尽或者其他进程需要cpu时才触发软中断进行发送。</li>
<li>网络设备子系统的队列和网卡驱动的 Ring Buffer 实际上是两个不同的概念<ul>
<li>网络设备子系统的队列是在内核网络栈中的软件队列，当数据包（skb）准备发送时，它首先被放入这个软件队列，这个队列主要用于流量控制、QoS（服务质量）管理等目的</li>
<li>网卡驱动的 Ring Buffer是一个硬件级别的队列，Ring Buffer 存储的不是完整的 skb，而是指向内存中数据包的描述符。</li>
<li>Ring Buffer 包含两个主要的数组，两个数组相同index下对应存储了同一个skb，只不过内核需要的是skb，网卡需要具体的物理地址，通过此设计当网卡发送完毕后，内核通过同一个index能定位到skb从而进行清理等工作。<ol>
<li>描述符数组（Descriptor Ring）主要是网卡使用</li>
<li>缓冲区信息数组（Buffer Info Array）主要是内核使用</li>
</ol>
</li>
</ul>
</li>
<li>在监控内核发送数据消耗的cpu时，应该将sy、si都考虑进来<ul>
<li>网络包发送过程中，用户进程(在内核态)完成了绝大部分的工作，甚至连调用驱动的工作都干了。只有当内核态进程被切走前才会发起软中断。发送过程中，绝大部分（90%）以上的开销都是在用户进程内核态消耗掉的。</li>
<li>只有一少部分情况才会触发软中断（NET_TX类型），由软中断ksoftirqd线程来发送。</li>
</ul>
</li>
<li>在服务器上查看&#x2F;proc&#x2F;softirqs，为什么NET_RX比NET_TX大的多的多？<ul>
<li>当数据发送完毕后，通过硬中断的方式来通知驱动发送完成，但是硬中断无论是数据接收，还是发送完毕，触发的软中断都是NET_RX_SOFTIRQ。</li>
<li>对于读来说，都是需要经过NET_RX软中断的，都走ksoftirqd内核线程，而对于发送来说，绝大部分工作都是在用户进程内核态处理了，只有系统态配额用尽才发出NET_TX，让软中断上。</li>
</ul>
</li>
</ul>
<h3 id="发送网络数据的时候都涉及哪些内存拷贝"><a href="#发送网络数据的时候都涉及哪些内存拷贝" class="headerlink" title="发送网络数据的时候都涉及哪些内存拷贝?"></a>发送网络数据的时候都涉及哪些内存拷贝?</h3><blockquote>
<p>指待发送数据的内存拷贝</p>
</blockquote>
<ol>
<li>第一次拷贝操作是在内核申请完skb之后，这时候会将用户传递进来的buffer里的数据内容都拷贝到skb。如果要发送的数据量比较大，这个拷贝操作开销不小。</li>
<li>第二次拷贝操作是从传输层进入网络层的时候，每一个skb都会被克隆出来一个新的副本。目的是保留原始的skb，当网络发现对方没有返回ack的时候，还可以重新发送，以实现TCP中要求的可靠传输，不过这次只是浅拷贝，只拷贝skb描述符本身，所指向的数据还是复用的。</li>
<li>第三次拷贝不是必须的，只有当IP层发现skb大于MTU时才需要进行。此时会再申请额外的skb，并讲究原来的skb拷贝为多个小的skb。</li>
</ol>
]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>网络</tag>
        <tag>socket</tag>
      </tags>
  </entry>
  <entry>
    <title>linux内核接收网络包</title>
    <url>/2025/02/09/wang-luo/linux-nei-he-jie-shou-wang-luo-bao/posts/undefined/</url>
    <content><![CDATA[<h3 id="RingBuffer"><a href="#RingBuffer" class="headerlink" title="RingBuffer"></a>RingBuffer</h3><h4 id="RingBuffer到底是什么"><a href="#RingBuffer到底是什么" class="headerlink" title="RingBuffer到底是什么?"></a>RingBuffer到底是什么?</h4><blockquote>
<p>是内存中的一块特殊区域，环形队列是笼统的说法，实际上包括<code>igb_rx_buffer</code> 环形队列数组、<code>e1000_adv_rx_desc</code> 环形队列数组及众多的skb</p>
</blockquote>
<p><img data-src="/images/socket_02_01.png" alt="img"></p>
<p>网卡在收到数据的时候以<code>DMA</code> 方式将包写到RingBuffer中。软中断收包的时候来这里将skb取走，并申请新的skb重新挂上去。</p>
<p>RingBuffer内存是预先分配的还是动态分配的？</p>
<p>指针数组是预先分配好的，而skb虽然也会预先分配好，但是在后面的收包过程中会不断的动态地分配申请</p>
<h4 id="RingBuffer为什么会丢包？"><a href="#RingBuffer为什么会丢包？" class="headerlink" title="RingBuffer为什么会丢包？"></a>RingBuffer为什么会丢包？</h4><ul>
<li>RingBuffer是有大小和长度限制的</li>
<li>使用 <code>ethtool -g eth0</code> 命令查看长度，Pre-set maximums 指的是最大值，Current hardware settings 表示当前设置，下图表示最大允许1024，目前设置为1024</li>
</ul>
<p><img data-src="/images/socket_02_02.png" alt="img"></p>
<ul>
<li>查看是否有溢出情况发生  <code>ethtool -S eth0</code>，如果有溢出情况发生(ifconfig中体现为overruns指标增长)，表示有包因为RingBuffer装不下而被丢弃了，解决思路有两种<ul>
<li>加大RingBuffer长度 <code>ethtool -G eth0 rx 4096 tx 4096</code> ，此种方式只是临时解决，治标不治本</li>
<li>开启多队列提升网络性能，打散队列的亲核性</li>
<li>现在主流网卡基本上都支持多队列，通过<code>ethtool -l eth0</code> 进行查看，下图表示当前网卡支持的最大队列数是2，当前开启的也是2，通过sysfs也可以看到真正生效的队列数量。</li>
<li><img data-src="/images/socket_02_03.png" alt="img"></li>
<li><img data-src="/images/socket_02_04.png" alt="img"></li>
<li>加大队列数量，可以使用 <code>ethtool -L eth0 combined 32</code> </li>
<li>如果发现某个cpu核心si特别高，可以考虑调整队列亲和的cpu核心<ul>
<li><code>cat /proc/interrupts</code>查看队列的硬件硬中断，下图显示输入队列0的中断号是25，队列1的中断号是27，通过这个中断号对应的<code>smp_affinity</code>可以查看到亲和的cpu核是哪个。下图显示的2在二进制中代表第二位是1，所以表示第2个cpu核心——CPU2</li>
<li><img data-src="/images/socket_02_05.png" alt="img"></li>
<li><img data-src="/images/socket_02_06.png" alt="img"></li>
<li>每个队列都会有独立的、不同的中断号。所以不同的队列在将数据收取到自己的RingBuffer后，可以分别向不同的CPU发起硬中断通知。而在硬中断的处理中，发起软中断是基于当前核心的，这意味着<strong>哪个核响应的硬中断，那么该硬中断发起的软中断任务就必然由这个核来处理</strong>。</li>
<li>通过设置每个队列中断号上的<code>smp_affinity</code>，将各个队列的硬中断打散到不同的cpu上。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="网络相关的硬中断、软中断都是什么"><a href="#网络相关的硬中断、软中断都是什么" class="headerlink" title="网络相关的硬中断、软中断都是什么?"></a>网络相关的硬中断、软中断都是什么?</h3><p> 在网卡将数据放到<code>RingBuffer</code> 之后，接着就发起<code>硬中断</code>，通知cpu进行处理。不过在硬中断的上下文里做的工作很少，将传过来的<code>poll_list</code> 添加到每个cpu变量<code>softnet_data</code> 的 <code>poll_list</code> 里面，接着触发<code>软中断</code> <code>NET_RX_SOFTIRQ</code>。在软中断中对softnet_data的设备列表poll_list进行遍历，执行网卡驱动提供的poll来收取网络包。处理完成后会送到协议栈的ip_rcv、udp_rcv、tcp_rcv_v4等函数中</p>
<p>poll_list 是个双向链表，存储待处理NAPI实例的链表。</p>
<p>一个网卡驱动程序通常会注册一个NAPI结构(struct napi_struct)，这个结构基本约等于一个接收队列，目的是为了减少硬中断的次数。在高并发网络中，频繁的接收到网络包导致频繁触发硬中断，浪费了CPU性能，通过NAPI一个队列中接收到网络包后将此队列信息传递给软中断，软中断处理程序在处理的时候先停止触发硬中断，专注接收包的处理，处理完成后再打开硬中断触发，大大减少了硬中断的触发。</p>
<h3 id="ksoftirqd内核线程是用来干嘛的"><a href="#ksoftirqd内核线程是用来干嘛的" class="headerlink" title="ksoftirqd内核线程是用来干嘛的?"></a>ksoftirqd内核线程是用来干嘛的?</h3><ul>
<li>机器上有几核，内核就会创建几个ksoftirqd线程出来</li>
<li>内核线程ksoftirqd包含了所有的软中断处理逻辑，软中断信息可以通过 <code>cat /proc/softirqs</code> 命令进行查看</li>
</ul>
<p><img data-src="/images/socket_02_07.png" alt="img"></p>
<h3 id="tcpdump是如何工作的？"><a href="#tcpdump是如何工作的？" class="headerlink" title="tcpdump是如何工作的？"></a>tcpdump是如何工作的？</h3><blockquote>
<p>tcpdump工作在设备层，是通过虚拟协议的方式工作的。通过调用packet_create将抓包函数以协议的形式挂到ptype_all上。这个函数会将包送到协议栈函数(ip_rcv、arp_rcv)之前，将包先送到ptype_all抓包点。</p>
</blockquote>
<ul>
<li>iptable&#x2F;netfilter 主要是在IP、ARP等层实现的。如果配置过于复杂的规则，则会消耗过多的cpu，加大网络延迟</li>
<li>tcpdump工作在设备层，将包送到ip层以前就能处理，而netfilter工作在IP、ARP等层，从下图来看，netfilter工作在tcpdump之后，所以iptable封禁规则不影响tcpdump抓包；但是发包过程恰恰相反，发包的时候netfilter先进行工作，在协议层就被过滤掉了，所以tcpdump什么都看不到。</li>
</ul>
<p><img data-src="/images/socket_02_08.png" alt="img"></p>
<h3 id="网络接收过程中的CPU开销如何查看？"><a href="#网络接收过程中的CPU开销如何查看？" class="headerlink" title="网络接收过程中的CPU开销如何查看？"></a>网络接收过程中的CPU开销如何查看？</h3><blockquote>
<p>在网络包的接收过程中，主要工作集中在硬中断和软中断上，二者的消耗可以通过top命令进行查看</p>
</blockquote>
<ul>
<li>输入top命令后，再输入1即可查看。其中hi是CPU处理硬中断的开销，si是处理软中断的开销，都是以百分比的形式展现的。</li>
</ul>
<p><img data-src="/images/socket_02_09.png" alt="img"></p>
]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>网络</tag>
        <tag>socket</tag>
      </tags>
  </entry>
  <entry>
    <title>抓包相关</title>
    <url>/2025/02/09/wang-luo/zhua-bao-xiang-guan/posts/undefined/</url>
    <content><![CDATA[<ul>
<li>查看路由表信息<ul>
<li>可以显示数据包的路由规则，告诉我们去往不同目标IP时会使用哪个网卡，方便指定网卡抓包</li>
<li><code>netstat -nr</code> 所有系统均可使用，n表示以数字形式显示地址和端口，r表示route</li>
<li><code>ip route</code> linux下使用，替代 netstat -r</li>
<li><code>ss</code>linux下使用，替代 netstat</li>
</ul>
</li>
<li>确认号(ack)计算规则<ul>
<li>普通数据包：ack &#x3D; 对方seq + len</li>
<li>SYN&#x2F;FIN包：ack &#x3D; 对方seq + len + 1</li>
<li>“我已经收到到这个位置的数据了”  “你下次就从这个位置继续发”</li>
</ul>
</li>
<li>seq <ul>
<li>不是包的唯一标识，而是数据流的位置标记</li>
<li>表示”我之后的数据会从这个位置开始发”</li>
<li>下一个包的seq等于对端确认的ack，seq、ack本质上都是流的序号，ack表示对端确认到了这个位置，自然我端需要从此为止发送数据</li>
</ul>
</li>
<li>某些场景下挥手时 FIN+ACK可能合并为一个包<ul>
<li>延迟确认的场景下，FIN+ACK可能合并为一个包</li>
</ul>
</li>
<li>LSO<ul>
<li>传输层不负责拆包处理，而是将数据直接传递给网卡，交给网卡负责分段</li>
<li>传统网络是应用层把数据交给TCP层，TCP层根据MSS大小进行分段（cpu负责）</li>
<li>启用LSO之后，TCP层直接把数据块传给网卡， 让网卡负责分段工作</li>
<li>优点在于节省了cpu资源，缺点在数据发送方抓包的时候可能看到一个分段前，超过MSS的大包</li>
</ul>
</li>
<li>数据包分段<ul>
<li>传输层分段(TCP分段)<ul>
<li>tcp会根据mss进行分段，一般mss的长度是MTU-40，同时会将IP层的flags打上DF标记避免ip分片</li>
<li>tcp层分段的好处是支持超时重传和快速重传等机制保证可靠性</li>
<li>有时候TCP头不止20字节，所以会侵占一些MSS的空间，比如用作 TCP Options，这样传输层真正用来承载的字节数 &#x3D; MTU(1500) - 20(ip header) - 20(tcp header) - length(Tcp Options)</li>
<li>TCP连接必须进行三次握手，在前两个握手包中双方互相声明自己的MSS，双方适配得到共识的MTU，这样就不会出现客户端发送的MTU大于接收方的情况</li>
</ul>
</li>
<li>网络层分段(UDP)<ul>
<li>ip层分片，丢失一个分片包就需要整个包重传</li>
<li>使用udp协议若不在应用层做好分段处理，就可能由于分片丢包重传导致性能地下</li>
<li>Udp 没有MSS的概念，全部数据移交给网络层</li>
</ul>
</li>
<li>接收方如何重组分段包<ul>
<li>将ID相同的分片按照off值（偏移量）进行重组</li>
<li>接收方通过Flags下面的的 <code>More Fragments = 0</code> 判断是不是最后一个分片，如果是最后一个分片了，可以开始重组分片了</li>
</ul>
</li>
</ul>
</li>
<li>Windos Scale<ul>
<li>TCP协议中只给接收窗口(win)预留了16个比特，意味着最大只能表示 65535 字节</li>
<li>随着网络带宽越来越大，预留的16个比特已经不够用了，RFC 1323 提供了一个创意，在三次握手时双方都把一个叫 <code>Windows Scale</code> 的值告知对方，对方收到后会把这个值当做2的指数，算出来的值再作为接收窗口的系数</li>
<li>假设 Windos Scale &#x3D; 3，win &#x3D; 10，那么实际的接收窗口 &#x3D; 10 * 2^3 &#x3D; 80</li>
<li>！！如果在三次握手之后才开始抓包，就无法获取到Windos Scale，只能显示出没有系数的大小，这是不准确的</li>
</ul>
</li>
<li>TTL(Time to Live)<ul>
<li>TTL 初始值一般为64</li>
<li>RFC 1812 一个网络包的TTL每减去1就意味着它经过一次路由</li>
<li>TTL一般可以用来验证网络拓扑，比如当前收到的包具体是哪个服务器发出的</li>
</ul>
</li>
</ul>
<h3 id="TCP-流量控制与窗口机制"><a href="#TCP-流量控制与窗口机制" class="headerlink" title="TCP 流量控制与窗口机制"></a>TCP 流量控制与窗口机制</h3><ol>
<li><h4 id="TCP头部Win字段"><a href="#TCP头部Win字段" class="headerlink" title="TCP头部Win字段"></a>TCP头部Win字段</h4></li>
</ol>
<ul>
<li>Win字段表示发送方的接收窗口大小(rwnd)</li>
<li>告知对方自己还能接收多少数据</li>
<li>动态变化：Win &#x3D; 接收缓冲区大小 - 已接收但未处理的数据量</li>
</ul>
<h4 id="2-流量控制机制"><a href="#2-流量控制机制" class="headerlink" title="2.  流量控制机制"></a>2.  流量控制机制</h4><h5 id="2-1-接收窗口-rwnd"><a href="#2-1-接收窗口-rwnd" class="headerlink" title="2.1   接收窗口(rwnd)"></a>2.1   接收窗口(rwnd)</h5><ul>
<li>通过TCP头部Win字段告知对方</li>
<li>反映接收方的处理能力</li>
<li>防止接收方缓冲区溢出</li>
<li>由应用程序处理速度决定</li>
</ul>
<h5 id="2-2-拥塞窗口-cwnd"><a href="#2-2-拥塞窗口-cwnd" class="headerlink" title="2.2  拥塞窗口(cwnd)"></a>2.2  拥塞窗口(cwnd)</h5><p><img data-src="/images/socket_02_11.jpeg" alt="img"></p>
<p><img data-src="/images/socket_02_12.png" alt="img"></p>
<ul>
<li>发送方内部维护，不需要告知对方</li>
<li>反映网络的承载能力</li>
<li>防止网络拥塞</li>
<li>由网络状况动态调整</li>
<li>拥塞窗口可以通过估算在途字节数进行计算，在途字节数 &#x3D; seq + len - ack，简单来说就是发送方这边发送过去的字节数减去对端ack的字节数得到在途字节数，那么拥塞窗口怎么确定最后一个数据包呢，找到第一个发生重传的数据包，根据此数据包进行过滤，得到最后一个发送的数据包以及ack包，就能计算在途字节数了，当然这种方式只是估算，需要采样几次，去最低的拥塞点作为拥塞窗口</li>
</ul>
<h5 id="2-3-实际发送控制"><a href="#2-3-实际发送控制" class="headerlink" title="2.3 实际发送控制"></a>2.3 实际发送控制</h5><blockquote>
<p>发送窗口大小 &#x3D; min(对方通告的win, 本地的cwnd)</p>
</blockquote>
]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>网络</tag>
        <tag>tcp</tag>
        <tag>抓包</tag>
      </tags>
  </entry>
  <entry>
    <title>raft</title>
    <url>/2025/02/09/fen-bu-shi/suan-fa/raft/posts/undefined/</url>
    <content><![CDATA[<h2 id="Raft-的核心目标和基本工作原理"><a href="#Raft-的核心目标和基本工作原理" class="headerlink" title="Raft 的核心目标和基本工作原理"></a>Raft 的核心目标和基本工作原理</h2><p>核心目标：</p>
<ul>
<li>在分布式系统中达成共识，实现强一致性。</li>
<li>在保证一致性的基础上进行可靠的数据复制。</li>
</ul>
<p>基本工作原理：</p>
<ul>
<li>领导者选举：使用随机化的选举超时机制。</li>
<li>日志复制：采用 WAL（Write-Ahead Logging）方式。</li>
<li>安全性保证：确保只有包含全部已提交日志的节点才能成为领导者。</li>
<li>成员管理：支持动态的成员变更。</li>
</ul>
<p>关键特性：</p>
<ul>
<li>将问题分解为相对独立的子问题：领导者选举、日志复制和安全性。</li>
<li>使用 term（任期）作为逻辑时钟，管理整个集群的时序。</li>
<li>要求多数节点确认以提交日志，保证数据安全性。</li>
</ul>
<h2 id="Term-的概念和作用"><a href="#Term-的概念和作用" class="headerlink" title="Term 的概念和作用"></a>Term 的概念和作用</h2><p>定义：</p>
<ul>
<li>Term 是 Raft 中的逻辑时钟概念，表示领导者的任期。</li>
<li>每个 term 由一次选举开始，可能有一个领导者，也可能没有（选举失败）。</li>
</ul>
<p>作用：</p>
<ul>
<li>标识集群的逻辑时间，用于检测过时的信息。</li>
<li>在选举中确保新领导者包含所有已提交的日志。</li>
<li>在网络分区恢复后，帮助识别和废除旧的领导者。</li>
<li>在所有 Raft 的决策过程中起关键作用，如日志复制、提交判断等。</li>
</ul>
<p>更新机制：</p>
<ul>
<li>节点在开始新选举时增加自己的 term。</li>
<li>节点在收到包含更高 term 的消息时更新自己的 term。</li>
</ul>
<h2 id="领导者选举过程"><a href="#领导者选举过程" class="headerlink" title="领导者选举过程"></a>领导者选举过程</h2><p>触发条件：</p>
<ul>
<li>Follower 在选举超时时间内没有收到来自 Leader 的心跳。</li>
</ul>
<p>选举步骤：</p>
<ul>
<li>Follower 转变为 Candidate，增加当前 term，投票给自己。</li>
<li>发送 RequestVote RPC 给其他节点，包含自己的 term 和最后一条日志的 index 和 term。</li>
<li>其他节点根据以下规则决定是否投票： <ul>
<li>如果接收到的 term 大于自己的 term，则更新自己的 term 并投票。</li>
<li>如果 term 相同，比较日志的新旧程度（先比较最后一条日志的 term，再比较 index）。</li>
<li>如果接收到的 term 小于自己的 term，拒绝投票并返回自己的 term。</li>
</ul>
</li>
<li>如果 Candidate 收到多数选票，则成为新的 Leader。</li>
<li>如果在等待过程中收到更高 term 的消息，则转为 Follower。</li>
</ul>
<p>防止选票分裂：</p>
<ul>
<li>使用随机化的选举超时时间，减少多个节点同时发起选举的可能性。</li>
</ul>
<p>预选票机制（优化）：</p>
<ul>
<li>在正式选举前进行预选票阶段，不增加 term。</li>
<li>有助于防止网络分区后的不必要 term 增加。</li>
</ul>
<h2 id="日志一致性保证"><a href="#日志一致性保证" class="headerlink" title="日志一致性保证"></a>日志一致性保证</h2><p>Log Matching Property: </p>
<ul>
<li>如果两个日志在相同索引位置的日志条目具有相同的 term，则这两个日志在该索引之前的所有条目都相同。</li>
</ul>
<p>实现机制：</p>
<ul>
<li>Leader 在 AppendEntries RPC 中包含 prevLogIndex 和 prevLogTerm。</li>
<li>Follower 在接收新日志前，检查自己在 prevLogIndex 位置的日志条目的 term 是否与 prevLogTerm 匹配。</li>
<li>如果匹配，则接受新的日志条目；如果不匹配，则拒绝并返回冲突信息。</li>
<li>Leader 收到拒绝后，递减 nextIndex 并重试，直到找到匹配点。</li>
</ul>
<p>这种机制通过递归性质保证了所有之前的日志也是一致的。</p>
<h2 id="commitIndex-和-lastApplied"><a href="#commitIndex-和-lastApplied" class="headerlink" title="commitIndex 和 lastApplied"></a>commitIndex 和 lastApplied</h2><p>commitIndex: </p>
<ul>
<li>主要在 Leader 上维护。</li>
<li>表示最后一个已知被提交（即，被多数节点复制）的日志条目的索引。</li>
<li>更新规则：Leader 找出 matchIndex 中超过半数节点都大于等于的最大值，且对应日志的 term 等于当前 term。</li>
</ul>
<p>lastApplied: </p>
<ul>
<li>在所有节点上维护。</li>
<li>表示最后一个被应用到状态机的日志条目的索引。</li>
<li>更新规则：成功将日志应用到状态机后更新。</li>
</ul>
<p>关系：lastApplied ≤ commitIndex</p>
<p>Follower 更新 commitIndex：通过 Leader 的 AppendEntries RPC 中的 leaderCommit 字段更新。</p>
<h2 id="网络分区（脑裂）的处理"><a href="#网络分区（脑裂）的处理" class="headerlink" title="网络分区（脑裂）的处理"></a>网络分区（脑裂）的处理</h2><p>防止脑裂的核心机制：</p>
<ul>
<li>要求多数节点的同意才能选举 Leader 和提交日志。</li>
</ul>
<p>具体表现：</p>
<ul>
<li>在网络分区情况下，只有包含多数节点的分区能选出新 Leader。</li>
<li>少数派分区可能会不断尝试选举，但无法获得多数选票，因此不会成功。</li>
<li>当网络分区恢复时，较高 term 的 Leader 会使其他节点回归到 Follower 状态。</li>
</ul>
<p>优化：使用预选票机制减少不必要的 term 增加。</p>
<h2 id="成员变更过程"><a href="#成员变更过程" class="headerlink" title="成员变更过程"></a>成员变更过程</h2><p>两阶段过程：</p>
<p>第一阶段（联合共识）：</p>
<ul>
<li>Leader 创建包含新旧配置的特殊日志条目（C_old+C_new）。</li>
<li>复制这个日志到集群中的多数节点（包括新旧配置中的节点）。</li>
<li>在这个阶段，所有决策（日志提交、选举）需要同时满足新旧配置的多数要求。</li>
</ul>
<p>第二阶段（新配置）：</p>
<ul>
<li>当第一阶段的日志被提交，且新节点已经充分同步后，Leader 创建只包含新配置的日志条目（C_new）。</li>
<li>当这个新配置日志被提交后，集群完全切换到新配置。</li>
</ul>
<p>设计原因：</p>
<ul>
<li>确保在配置变更过程中不会出现决策冲突。</li>
<li>允许新节点在参与集群决策之前有时间同步日志。</li>
<li>保证在任何时候都有一个明确的、一致的集群配置。</li>
</ul>
<h2 id="日志压缩"><a href="#日志压缩" class="headerlink" title="日志压缩"></a>日志压缩</h2><p>快照机制：</p>
<ul>
<li>定期创建包含完整状态机状态的快照。</li>
<li>创建快照后，可以安全地丢弃该点之前的所有日志。</li>
<li>快照包含：最后应用的日志的 index 和 term，最新的集群配置。</li>
</ul>
<p>用途：</p>
<ul>
<li>减少存储空间使用。</li>
<li>加速重启过程。</li>
<li>帮助落后太多的节点快速赶上（通过直接发送快照）。</li>
</ul>
<p>针对特定应用的优化：</p>
<ul>
<li>对于 KV 存储，可以只保留每个 key 的最新值。</li>
</ul>
<h2 id="读操作优化"><a href="#读操作优化" class="headerlink" title="读操作优化"></a>读操作优化</h2><p>挑战：确保读取的是最新数据。</p>
<p>优化策略：</p>
<ul>
<li>Leader 读取： <ul>
<li>Leader 在响应读请求前确认自己仍是当前 Leader（通过与多数节点通信）。</li>
<li>使用租约机制减少确认开销。</li>
</ul>
</li>
<li>Follower 读取（非强一致性）： <ul>
<li>直接从 Follower 读取，用于对一致性要求不高的场景。</li>
<li>可能读到稍旧的数据，但减轻了 Leader 的负担。</li>
</ul>
</li>
<li>读索引（Read Index）： <ul>
<li>Leader 记录当前的 commitIndex，确认 leadership，然后等待 applyIndex 赶上该 commitIndex。</li>
</ul>
</li>
<li>租约读（Lease Read）： <ul>
<li>Leader 维护一个租约，在租约内不与 Followers 通信即可响应读请求。</li>
</ul>
</li>
</ul>
<h2 id="Raft-vs-Paxos"><a href="#Raft-vs-Paxos" class="headerlink" title="Raft vs Paxos"></a>Raft vs Paxos</h2><p>设计理念：</p>
<ul>
<li>Raft 设计目标是易于理解和实现。</li>
<li>Paxos 更加理论化和通用。</li>
</ul>
<p>结构：</p>
<ul>
<li>Raft 将问题分解为领导选举、日志复制等子问题。</li>
<li>Paxos 是一个更单一的协议。</li>
</ul>
<p>领导机制：</p>
<ul>
<li>Raft 有明确的领导者选举过程。</li>
<li>Paxos 中领导角色不那么明确。</li>
</ul>
<p>日志特性：</p>
<ul>
<li>Raft 保证日志是连续的。</li>
<li>Paxos 允许日志中有”空洞”。</li>
</ul>
<p>实现复杂度：</p>
<ul>
<li>Raft 通常更容易实现和调试。</li>
<li>Paxos 的正确实现往往更复杂。</li>
</ul>
]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>算法</tag>
        <tag>raft</tag>
      </tags>
  </entry>
  <entry>
    <title>kafka-consumer</title>
    <url>/2025/02/09/xiao-xi-dui-lie/kafka/consumer/posts/undefined/</url>
    <content><![CDATA[<h2 id="重要参数"><a href="#重要参数" class="headerlink" title="重要参数"></a>重要参数</h2><table>
<thead>
<tr>
<th align="left">配置项</th>
<th align="left">默认值</th>
<th align="left">说明</th>
<th align="left">示例</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><strong>bootstrap.servers</strong></td>
<td align="left"></td>
<td align="left">Kafka broker 地址</td>
<td align="left"><code>*properties*.put(ProducerConfig.*BOOTSTRAP_SERVERS_CONFIG*, *brokerList*);</code></td>
</tr>
<tr>
<td align="left"><strong>key.deserializer</strong></td>
<td align="left"></td>
<td align="left">Key 反序列化 实现 Deserializer 接口</td>
<td align="left"><code>*properties*.put(ConsumerConfig.*KEY_DESERIALIZER_CLASS_CONFIG*, StringDeserializer.class.getName());</code></td>
</tr>
<tr>
<td align="left"><strong>value.deserializer</strong></td>
<td align="left"></td>
<td align="left">Value 反序列化实现 Deserializer 接口</td>
<td align="left"><code>*properties*.put(ConsumerConfig.*VALUE_DESERIALIZER_CLASS_CONFIG*, StringDeserializer.class.getName());</code></td>
</tr>
<tr>
<td align="left"><strong>group.id</strong></td>
<td align="left"></td>
<td align="left">消费组 ID</td>
<td align="left"><code>*properties*.put(ConsumerConfig.*GROUP_ID_CONFIG*, *groupId*);</code></td>
</tr>
<tr>
<td align="left"><strong>enable.auto.commit</strong></td>
<td align="left">true</td>
<td align="left">是否开启自动提交默认为 true</td>
<td align="left"><code>*properties*.put(ConsumerConfig.*ENABLE_AUTO_COMMIT_CONFIG*, false);</code></td>
</tr>
<tr>
<td align="left"><strong>auto.commit.interval.ms</strong></td>
<td align="left">5000</td>
<td align="left">自动提交间隔时间，只有在 enable.auto.commit 设置为 true 时生效，默认是 5s! ! offset 提交时间点&#x3D;max（单次 poll 时间， auto.commit.interval.ms）</td>
<td align="left"><code>*properties*.put(ConsumerConfig.*AUTO_COMMIT_INTERVAL_MS_CONFIG*, 5000);</code></td>
</tr>
<tr>
<td align="left"><strong>auto.offset.reset</strong></td>
<td align="left">latest</td>
<td align="left">从最早的消息开始消费 默认是 latest，此参数表示当前消费组在没有 offset 的情况下，从哪里开始消费这里的没有 offset 指的是消费组第一次消费或者_consumer_offsets 主题中没有当前消费组的 offset! ! 建议设置为 earliest，否则扩分区时，新增加的消费者可能丢失新分区产生的数据；设置为 earliest 时业务上需要做好幂等处理</td>
<td align="left"><code>*properties*.put(ConsumerConfig.*AUTO_OFFSET_RESET_CONFIG*, &quot;earliest&quot;);</code></td>
</tr>
<tr>
<td align="left"><strong>max.poll.records</strong></td>
<td align="left">500</td>
<td align="left">一次拉取请求中拉取的最大消息数量 默认是 500 条! ! 建议调整此参数，业务处理时间超过 max.poll.interval.ms 会导致 rebalance，所以这里的单次拉取的数据量需要考虑处理时间；max.poll.records &lt; max.poll.interval.ms &#x2F; 单条消息处理时间</td>
<td align="left"><code>*properties*.put(ConsumerConfig.*MAX_POLL_RECORDS_CONFIG*, 500);</code></td>
</tr>
<tr>
<td align="left"><strong>max.poll.interval.ms</strong></td>
<td align="left">5 * 60 * 1000</td>
<td align="left">拉取消息线程最长空闲时间，默认是 5 分钟，若超过这个间隔还没有发起 poll 请求，消费者会认为消费者挂掉了，然后触发 rebalance因为 poll 方法还涉及业务处理，所以如果业务处理时间过长，那么需要适当增大此值，或者减少单次拉取的消息数量! ! 如果业务处理时间较长，一定要增加此配置，否则会导致 rebalance</td>
<td align="left"><code>*properties*.put(ConsumerConfig.*MAX_POLL_INTERVAL_MS_CONFIG*, 5 * 60 * 1000);</code></td>
</tr>
<tr>
<td align="left"><strong>heartbeat.interval.ms</strong></td>
<td align="left">3 * 1000</td>
<td align="left">配置消费者的最大心跳间隔时间，默认是 3s心跳间隔时间是指消费者发送心跳给 broker 的时间间隔必须比 session.timeout.ms 小，一般是 session.timeout.ms 的 1&#x2F;3</td>
<td align="left"><code>*properties*.put(ConsumerConfig.*HEARTBEAT_INTERVAL_MS_CONFIG*, 3 * 1000);</code></td>
</tr>
<tr>
<td align="left"><strong>session.timeout.ms</strong></td>
<td align="left">10 * 1000</td>
<td align="left">配置消费者与 broker 的会话超时时间，默认是 10s超过此时间 broker 没有收到消费者的心跳，那么 broker 会认为消费者挂掉了，然后触发 rebalance! ! 此参数不能配置过大！！</td>
<td align="left"></td>
</tr>
<tr>
<td align="left">fetch.max.bytes</td>
<td align="left">50 * 1024 * 1024</td>
<td align="left">一次请求从 kafka 中拉取的最大数据量，默认是 50M，此参数不是绝对的最大值，如果一条消息的大小比此参数还大，那么一次请求也会拉取这条消息</td>
<td align="left"><code>*properties*.put(ConsumerConfig.*FETCH_MAX_BYTES_CONFIG*, ConsumerConfig.*DEFAULT_FETCH_MAX_BYTES*);</code></td>
</tr>
<tr>
<td align="left">max.partition.fetch.bytes</td>
<td align="left">1 * 1024 * 1024</td>
<td align="left">一次请求从 kafka 中拉取单个分区的最大数据量，默认是 1M</td>
<td align="left"><code>*properties*.put(ConsumerConfig.*MAX_PARTITION_FETCH_BYTES_CONFIG*, ConsumerConfig.*DEFAULT_MAX_PARTITION_FETCH_BYTES*);</code></td>
</tr>
<tr>
<td align="left">connections.max.idle.ms</td>
<td align="left">9 * 60 * 1000</td>
<td align="left">指定多久之后关闭闲置的连接，默认是 9 分钟</td>
<td align="left"><code>*properties*.put(ConsumerConfig.*CONNECTIONS_MAX_IDLE_MS_CONFIG*, 9 * 60 * 1000);</code></td>
</tr>
<tr>
<td align="left">receive.buffer.bytes</td>
<td align="left">64 * 1024</td>
<td align="left">设置 socket 接收消息缓冲区（SO_RCVBUF）的大小，默认是 64KB，如果设置为 -1，那么使用操作系统的默认值，如果 Consumer 与 Kafka 处于不同的数据中心，那么可以适当增大此值</td>
<td align="left"><code>*properties*.put(ConsumerConfig.*RECEIVE_BUFFER_CONFIG*, 64 * 1024);</code></td>
</tr>
<tr>
<td align="left">send.buffer.bytes</td>
<td align="left">128 * 1024</td>
<td align="left">设置 socket 发送消息缓冲区（SO_SNDBUF）的大小，默认是 128KB，如果设置为 -1，那么使用操作系统的默认值，如果 Consumer 与 Kafka 处于不同的数据中心，那么可以适当增大此值</td>
<td align="left"><code>*properties*.put(ConsumerConfig.*SEND_BUFFER_CONFIG*, 128 * 1024);</code></td>
</tr>
<tr>
<td align="left">request.timeout.ms</td>
<td align="left">30 * 1000</td>
<td align="left">配置 consumer 等待请求响应的最大时间，默认是 30s</td>
<td align="left"><code>*properties*.put(ConsumerConfig.*REQUEST_TIMEOUT_MS_CONFIG*, 30 * 1000);</code></td>
</tr>
</tbody></table>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">static</span> &#123;</span><br><span class="line">    properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, brokerList);</span><br><span class="line">    properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">    properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">    properties.put(ConsumerConfig.GROUP_ID_CONFIG, groupId);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 提交，默认是自动提交，间隔是5s</span></span><br><span class="line">    <span class="comment">// properties.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, true);</span></span><br><span class="line">    <span class="comment">// properties.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, 5000);</span></span><br><span class="line">    <span class="comment">// 调整为手动提交</span></span><br><span class="line">    properties.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, <span class="literal">false</span>);</span><br><span class="line">    <span class="comment">// 自动提交间隔时间，只有在enable.auto.commit设置为true时生效，默认是5s</span></span><br><span class="line">    properties.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, <span class="number">5000</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 从最早的消息开始消费 默认是latest，此参数表示当前消费组在没有offset的情况下，从哪里开始消费</span></span><br><span class="line">    <span class="comment">// 这里的没有offset指的是消费组第一次消费或者_consumer_offsets主题中没有当前消费组的offset</span></span><br><span class="line">    properties.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, <span class="string">&quot;earliest&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 一次请求从kafka中拉取的最大数据量，默认是50M，此参数不是绝对的最大值，如果一条消息的大小比此参数还大，那么一次请求也会拉取这条消息</span></span><br><span class="line">    properties.put(ConsumerConfig.FETCH_MAX_BYTES_CONFIG, ConsumerConfig.DEFAULT_FETCH_MAX_BYTES);</span><br><span class="line">    <span class="comment">// 一次请求从kafka中拉取单个分区的最大数据量，默认是1M</span></span><br><span class="line">    properties.put(ConsumerConfig.MAX_PARTITION_FETCH_BYTES_CONFIG, ConsumerConfig.DEFAULT_MAX_PARTITION_FETCH_BYTES);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 一次拉取请求中拉取的最大消息数量 默认是500条</span></span><br><span class="line">    properties.put(ConsumerConfig.MAX_POLL_RECORDS_CONFIG, <span class="number">500</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 指定多久之后关闭闲置的连接，默认是9分钟</span></span><br><span class="line">    properties.put(ConsumerConfig.CONNECTIONS_MAX_IDLE_MS_CONFIG, <span class="number">9</span> * <span class="number">60</span> * <span class="number">1000</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 设置socket接收消息缓冲区(SO_RCVBUF)的大小，默认是64KB，如果设置为-1，那么使用操作系统的默认值，如果Consumer与Kafka处于不同的数据中心，那么可以适当增大此值</span></span><br><span class="line">    properties.put(ConsumerConfig.RECEIVE_BUFFER_CONFIG, <span class="number">64</span> * <span class="number">1024</span>);</span><br><span class="line">    <span class="comment">// 设置socket发送消息缓冲区(SO_SNDBUF)的大小，默认是128KB，如果设置为-1，那么使用操作系统的默认值，如果Consumer与Kafka处于不同的数据中心，那么可以适当增大此值</span></span><br><span class="line">    properties.put(ConsumerConfig.SEND_BUFFER_CONFIG, <span class="number">128</span> * <span class="number">1024</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 配置consumer等待请求响应的最大时间，默认是30s</span></span><br><span class="line">    properties.put(ConsumerConfig.REQUEST_TIMEOUT_MS_CONFIG, <span class="number">30</span> * <span class="number">1000</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// todo-wl 配置消费者的事务隔离级别</span></span><br><span class="line">    <span class="comment">// properties.put(ConsumerConfig.ISOLATION_LEVEL_CONFIG, &quot;read_committed&quot;);</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// !! 配置消费者的最大心跳间隔时间，默认是3s</span></span><br><span class="line">    <span class="comment">// 心跳间隔时间是指消费者发送心跳给broker的时间间隔</span></span><br><span class="line">    <span class="comment">// 必须比session.timeout.ms小，一般是session.timeout.ms的1/3</span></span><br><span class="line">    properties.put(ConsumerConfig.HEARTBEAT_INTERVAL_MS_CONFIG, <span class="number">3</span> * <span class="number">1000</span>);</span><br><span class="line">    <span class="comment">// !! 配置消费者与broker的会话超时时间，默认是10s</span></span><br><span class="line">    <span class="comment">// 超过此时间broker没有收到消费者的心跳，那么broker会认为消费者挂掉了，然后触发rebalance</span></span><br><span class="line">    properties.put(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, <span class="number">10</span> * <span class="number">1000</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// !! 拉取消息线程最长空闲时间，默认是5分钟，若超过这个间隔还没有发起poll请求，消费者会认为消费者挂掉了，然后触发rebalance</span></span><br><span class="line">    <span class="comment">// 因为poll方法还涉及业务处理，所以如果业务处理时间过长，那么需要适当增大此值，或者减少单次拉取的消息数量</span></span><br><span class="line">    properties.put(ConsumerConfig.MAX_POLL_INTERVAL_MS_CONFIG, <span class="number">5</span> * <span class="number">60</span> * <span class="number">1000</span>);</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="Kafka-rebalance"><a href="#Kafka-rebalance" class="headerlink" title="Kafka-rebalance"></a>Kafka-rebalance</h2><ul>
<li><a href="https://redpanda.com/guides/kafka-performance/kafka-rebalancing">kafka-rebalancing</a></li>
<li>发生再平衡的场景<ul>
<li>消费者加入或离开</li>
<li>消费者遇到暂时故障或网络中断</li>
<li>消费者闲置时间过长</li>
<li>扩大了主题分区</li>
</ul>
</li>
<li>再平衡的副作用<ul>
<li>延迟增加</li>
<li>吞吐量降低</li>
<li>资源使用量增加</li>
<li>潜在的数据重复和丢失</li>
<li>复杂性增加</li>
</ul>
</li>
<li>减少再平衡的措施<ul>
<li>增加会话超时时间 session.timeout.ms，此参数不能设置太高，不然导致消费者长时间不活动进而导致消息堆积；heartbeat.interval.ms 此参数</li>
<li>​       需要小于 session.timeout.ms，一般是 1&#x2F;3</li>
<li>减少每个主题的分区，每个主题的分区过多会增加重新平衡的频率</li>
<li>增加轮训间隔时间，max.poll.interval.ms 配置规定了消费者被视为非活动并从组中移除前的最长空闲时间，增加此时间助于避免消费者组的频繁更改</li>
</ul>
</li>
<li>增量合作再平衡<ul>
<li>Kafka 2.4 中引入了增量合作再平衡协议，以最大程度地减少 Kafka 再平衡造成的中断。在传统的再平衡中，组中的所有消费者在重新平衡过程中停止使用数据，通常称为“停止世界效应”。这会导致数据处理延迟和中断。</li>
<li>增量合作再平衡协议将再平衡拆分为更小的子任务，消费者在这些子任务完成后继续使用数据。因此，重新平衡发生得更快，对数据处理的中断更少。</li>
<li>该协议还为再平衡过程提供了更精细的控制。例如，它允许使用者根据其当前负载和容量协商他们将使用的特定分区集。这可以防止单个使用者的过载，并确保以更平衡的方式分配分区。</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>消息队列</tag>
        <tag>中间件</tag>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title>kafka-producer</title>
    <url>/2025/02/09/xiao-xi-dui-lie/kafka/producer/posts/undefined/</url>
    <content><![CDATA[<h2 id="重要参数"><a href="#重要参数" class="headerlink" title="重要参数"></a>重要参数</h2><table>
<thead>
<tr>
<th align="left">配置项</th>
<th align="left">默认值</th>
<th align="left">说明</th>
<th align="left">示例</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><strong>bootstrap.servers</strong></td>
<td align="left"></td>
<td align="left">Kafka broker 地址</td>
<td align="left"><code>*properties*.put(ProducerConfig.*BOOTSTRAP_SERVERS_CONFIG*, *brokerList*);</code></td>
</tr>
<tr>
<td align="left"><strong>key.serializer</strong></td>
<td align="left"></td>
<td align="left">Key 序列化器实现 Serializer 接口</td>
<td align="left"><code>*properties*.put(ProducerConfig.*KEY_SERIALIZER_CLASS_CONFIG*, StringSerializer.class.getName());</code></td>
</tr>
<tr>
<td align="left"><strong>value.serializer</strong></td>
<td align="left"></td>
<td align="left">Value 序列化器实现 Serializer 接口</td>
<td align="left"><code>*properties*.put(ProducerConfig.*VALUE_SERIALIZER_CLASS_CONFIG*, StringSerializer.class.getName());</code></td>
</tr>
<tr>
<td align="left"><strong>acks</strong></td>
<td align="left">1</td>
<td align="left">指定分区中必须有多少个副本收到消息，生产者才认为消息写入成功，默认 1acks&#x3D;1 生产者发送消息到分区 leader，leader 将消息写入本地日志后即返回成功acks&#x3D;0 生产者发送消息到分区 leader，不等待 leader 写入本地日志，直接返回成功acks&#x3D;all&#x2F;acks&#x3D;-1 生产者发送消息到分区 leader，leader 将消息写入本地日志后，等待 ISR 中所有副本都写入成功后才返回成功 acks&#x3D;all 等价于 acks&#x3D;-1 并不一定最可靠，因为 ISR 中的副本可能会因为各种原因不可用，导致 ISR 副本只有 leader 节点一个，如果需要获得更高的可靠性，需要配置 min.insync.replicas 参数（broker 参数，建议配置大于 1 &amp; 小于副本数量），此参数表示 ISR 中至少有多少个副本是可用的</td>
<td align="left"><code>*properties*.put(ProducerConfig.*ACKS_CONFIG*, &quot;all&quot;);</code></td>
</tr>
<tr>
<td align="left"><strong>retries</strong></td>
<td align="left"></td>
<td align="left">配置重试次数，重试次数只限制于可重试的异常，不可重试的异常此参数无意义</td>
<td align="left"><code>*properties*.put(ProducerConfig.*RETRIES_CONFIG*, 10);</code></td>
</tr>
<tr>
<td align="left"><strong>retry.backoff.ms</strong></td>
<td align="left"></td>
<td align="left">重试的时间间隔</td>
<td align="left"><code>*properties*.put(ProducerConfig.*RETRY_BACKOFF_MS_CONFIG*, 100);</code></td>
</tr>
<tr>
<td align="left"><strong>max.in.flight.requests.per.connection</strong></td>
<td align="left">5</td>
<td align="left">配置单个连接最大缓存请求数量，发送的请求 ProducerBatch 会缓存到 InFlightRequests 中，此参数限制 InFlightRequests 的大小，默认 5，即每个连接最多只能缓存 5 个未响应的请求</td>
<td align="left"><code>*properties*.put(ProducerConfig.*MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION*, 5);</code></td>
</tr>
<tr>
<td align="left">request.timeout.ms</td>
<td align="left">30 * 1000</td>
<td align="left">Producer 等待请求响应的最长时间，默认 30s，如果在 30s 内没有收到响应，那么会重发消息这个参数需要比 broker 端的参数 replica.lag.time.max.ms（Follower 副本能够落后 Leader 副本的最长时间间隔，默认值是 10 秒）大，否则可能会出现消息丢失</td>
<td align="left"><code>*properties*.put(ProducerConfig.*REQUEST_TIMEOUT_MS_CONFIG*, 30 * 1000);</code></td>
</tr>
<tr>
<td align="left">linger.ms</td>
<td align="left">0</td>
<td align="left">指定生产者发送 ProducerBatch 之前等待更多消息加入到 ProducerBatch 的时间，默认 0，即立即发送，这个参数与 TCP 的 Nagle 算法类似</td>
<td align="left"><code>*properties*.put(ProducerConfig.*LINGER_MS_CONFIG*, 0);</code></td>
</tr>
<tr>
<td align="left">send.buffer.bytes</td>
<td align="left">128 * 1024</td>
<td align="left">设置 socket 发送缓冲区大小，默认 128k，如果设置为 -1，那么使用操作系统默认的大小</td>
<td align="left"><code>*properties*.put(ProducerConfig.*SEND_BUFFER_CONFIG*, 128 * 1024);</code></td>
</tr>
<tr>
<td align="left">interceptor.classes</td>
<td align="left"></td>
<td align="left">消息发送拦截器消息发送到 broker 之前拦截，可修改消息内容实现 ProducerInterceptor 接口</td>
<td align="left"><code>*properties*.put(ProducerConfig.*INTERCEPTOR_CLASSES_CONFIG*, ProducerInterceptorPrefix.class.getName());</code></td>
</tr>
<tr>
<td align="left">buffer.memory</td>
<td align="left">32 * 1024 * 1024</td>
<td align="left">缓存消息大小生产者主线程会将消息缓存到 RecordAccumulator 中，然后由 Sender 线程发送到 Kafka，这里的参数是 RecordAccumulator 的缓存大小，默认 32M</td>
<td align="left"><code>// 缓存消息大小，生产者主线程会将消息缓存到RecordAccumulator中，然后由Sender线程发送到Kafka，这里的参数是RecordAccumulator的缓存大小，默认32M *properties*.put(ProducerConfig.*BUFFER_MEMORY_CONFIG*, 32 * 1024 * 1024L);</code></td>
</tr>
<tr>
<td align="left">max.block.ms</td>
<td align="left">60 * 1000</td>
<td align="left">RecordAccumulator 缓存空间不足时，最大阻塞时间，默认 60s</td>
<td align="left"><code>// RecordAccumulator缓存空间不足时，最大阻塞时间，默认60s *properties*.put(ProducerConfig.*MAX_BLOCK_MS_CONFIG*, 60 * 1000);</code></td>
</tr>
<tr>
<td align="left">batch.size</td>
<td align="left">16 * 1024</td>
<td align="left">单次发送消息大小，kafka 会将消息组装为 ProducerBatch，此参数影响 ProducerBatch 的大小，如果消息小于此参数，则会通过 BufferPool 进行复用，默认 16k</td>
<td align="left"><code>*properties*.put(ProducerConfig.*BATCH_SIZE_CONFIG*, 16 * 1024);</code></td>
</tr>
<tr>
<td align="left">max.request.size</td>
<td align="left">1024 * 1024</td>
<td align="left">客户端能发送消息的最大值，默认 1M，不建议修改这个值，因为涉及到 broker 端的参数客户端能发送消息的最大值，默认 1M，不建议修改这个值，因为涉及到 broker 端的参数</td>
<td align="left"><code>*properties*.put(ProducerConfig.*MAX_REQUEST_SIZE_CONFIG*, 1024 * 1024);</code></td>
</tr>
<tr>
<td align="left">compression.type</td>
<td align="left">none</td>
<td align="left">消息压缩方式，默认是 none，支持 none、gzip、snappy、lz4，如果需要提升吞吐量，可以开启消息压缩</td>
<td align="left"><code>*properties*.put(ProducerConfig.*COMPRESSION_TYPE_CONFIG*, &quot;none&quot;);</code></td>
</tr>
<tr>
<td align="left">connections.max.idle.ms</td>
<td align="left">9 * 60 * 1000</td>
<td align="left">关闭闲置的连接，默认 9 分钟，如果生产者在 9 分钟内没有发送消息，那么生产者会关闭连接，如果生产者在 9 分钟内发送消息，那么生产者会重置闲置时间</td>
<td align="left"><code>*properties*.put(ProducerConfig.*CONNECTIONS_MAX_IDLE_MS_CONFIG*, 9 * 60 * 1000);</code></td>
</tr>
</tbody></table>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">static</span> &#123;</span><br><span class="line">    properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, brokerList);</span><br><span class="line">    properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line">    properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 发送拦截器</span></span><br><span class="line">    properties.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG, ProducerInterceptorPrefix.class.getName());</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 生产者发送配置</span></span><br><span class="line">    <span class="comment">// 缓存消息大小，生产者主线程会将消息缓存到RecordAccumulator中，然后由Sender线程发送到Kafka，这里的参数是RecordAccumulator的缓存大小，默认32M</span></span><br><span class="line">    properties.put(ProducerConfig.BUFFER_MEMORY_CONFIG, <span class="number">32</span> * <span class="number">1024</span> * <span class="number">1024L</span>);</span><br><span class="line">    <span class="comment">// RecordAccumulator缓存空间不足时，最大阻塞时间，默认60s</span></span><br><span class="line">    properties.put(ProducerConfig.MAX_BLOCK_MS_CONFIG, <span class="number">60</span> * <span class="number">1000</span>);</span><br><span class="line">    <span class="comment">// 单次发送消息大小，kafka会将消息组装为ProducerBatch，此参数影响ProducerBatch的大小，如果消息小于此参数，则会通过pBufferPool进行复用，默认16k</span></span><br><span class="line">    properties.put(ProducerConfig.BATCH_SIZE_CONFIG, <span class="number">16</span> * <span class="number">1024</span>);</span><br><span class="line">    <span class="comment">// 配置单个连接最大缓存请求数量，发送的请求ProducerBatch会缓存到InFlightRequests中，此参数限制InFlightRequests的大小，默认5，即每个连接最多只能缓存5个未响应的请求</span></span><br><span class="line">    properties.put(ProducerConfig.MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION, <span class="number">5</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 重要的生产者参数</span></span><br><span class="line">    <span class="comment">// 指定分区中必须有多少个副本收到消息，生产者才认为消息写入成功，默认1</span></span><br><span class="line">    <span class="comment">// acks=1 生产者发送消息到分区leader，leader将消息写入本地日志后即返回成功</span></span><br><span class="line">    <span class="comment">// acks=0 生产者发送消息到分区leader，不等待leader写入本地日志，直接返回成功</span></span><br><span class="line">    <span class="comment">// acks=all/acks=-1 生产者发送消息到分区leader，leader将消息写入本地日志后，等待ISR中所有副本都写入成功后才返回成功</span></span><br><span class="line">    <span class="comment">// acks=all 等价于 acks=-1 并不一定最可靠，因为ISR中的副本可能会因为各种原因不可用，导致ISR副本只有leader节点一个，如果需要获得更高的可靠性，需要配置 min.insync.replicas 参数，此参数表示ISR中至少有多少个副本是可用的</span></span><br><span class="line">    properties.put(ProducerConfig.ACKS_CONFIG, <span class="string">&quot;all&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 客户端能发送消息的最大值，默认1M，不建议修改这个值，因为涉及到broker端的参数</span></span><br><span class="line">    <span class="comment">// 此参数表示单次网络请求的大小，这次请求中可能包含很多个ProducerBatch</span></span><br><span class="line">    properties.put(ProducerConfig.MAX_REQUEST_SIZE_CONFIG, <span class="number">1024</span> * <span class="number">1024</span>);</span><br><span class="line">    <span class="comment">// 指定生产者发送ProducerBatch之前等待更多消息加入到ProducerBatch的时间，默认0，即立即发送，这个参数与TCP的Nagle算法类似</span></span><br><span class="line">    properties.put(ProducerConfig.LINGER_MS_CONFIG, <span class="number">0</span>);</span><br><span class="line">    <span class="comment">// 设置socket发送缓冲区大小，默认128k，如果设置为-1，那么使用操作系统默认的大小</span></span><br><span class="line">    properties.put(ProducerConfig.SEND_BUFFER_CONFIG, <span class="number">128</span> * <span class="number">1024</span>);</span><br><span class="line">    <span class="comment">// Producer等待氢气响应的最长时间，默认30s，如果在30s内没有收到响应，那么会重发消息</span></span><br><span class="line">    <span class="comment">// 这个参数需要比broker端的参数replica.lag.time.max.ms（Follower 副本能够落后 Leader 副本的最长时间间隔，默认值是 10 秒）大，否则可能会出现消息丢失</span></span><br><span class="line">    properties.put(ProducerConfig.REQUEST_TIMEOUT_MS_CONFIG, <span class="number">30</span> * <span class="number">1000</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 配置重试次数，重试次数只限制于可重试的异常，不可重试的异常此参数无意义</span></span><br><span class="line">    properties.put(ProducerConfig.RETRIES_CONFIG, <span class="number">10</span>);</span><br><span class="line">    <span class="comment">// 重试的时间间隔</span></span><br><span class="line">    properties.put(ProducerConfig.RETRY_BACKOFF_MS_CONFIG, <span class="number">100</span>);</span><br><span class="line">    <span class="comment">// 某些场景下消息的顺序是非常重要的，如果retry重试次数设置大于0 &amp; max.in.flight.requests.per.connection &gt; 1，那么可能会导致消息乱序</span></span><br><span class="line">    <span class="comment">// 比如第一批次消息发送失败，第二批次消息发送成功，第一批次消息重试发送成功，那么第一批次消息就会出现在第二批次消息之后</span></span><br><span class="line">    <span class="comment">// 建议如果需要保证消息的顺序，那么将max.in.flight.requests.per.connection设置为1，而不是设置重试次数为0，不过这样会导致吞吐量下降</span></span><br><span class="line">    <span class="comment">// ? todo-wl 如果重试次数=0，max.in.flight.requests.per.connection&gt;1，怎么保证消息是有序的？</span></span><br><span class="line">    <span class="comment">// -&gt; 因为单次网络包可能包含多个ProducerBatch，kafka在处理的时候会将多个ProducerBatch合并为一个请求，同时对于同一个分区的消息，kafka会保证消息的顺序，所以能保证消息是有序的</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 消息压缩方式，默认是none，支持none、gzip、snappy、lz4，如果需要提升吞吐量，可以开启消息压缩</span></span><br><span class="line">    properties.put(ProducerConfig.COMPRESSION_TYPE_CONFIG, <span class="string">&quot;none&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 关闭闲置的连接，默认9分钟，如果生产者在9分钟内没有发送消息，那么生产者会关闭连接，如果生产者在9分钟内发送消息，那么生产者会重置闲置时间</span></span><br><span class="line">    properties.put(ProducerConfig.CONNECTIONS_MAX_IDLE_MS_CONFIG, <span class="number">9</span> * <span class="number">60</span> * <span class="number">1000</span>);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 幂等性配置</span></span><br><span class="line"><span class="keyword">static</span> &#123;</span><br><span class="line">    <span class="comment">// 开启幂等性</span></span><br><span class="line">    properties.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG, <span class="literal">true</span>);</span><br><span class="line">    <span class="comment">// 幂等的原理是消费者会被分配一个pid，pid是一个递增的序列号，生产者每发送一条消息就会将&lt;PID,分区&gt;对应的序列号+1</span></span><br><span class="line">    <span class="comment">// 当发送消息时，会将seq发送到broker，broker内存中保存&lt;PID,分区&gt;对应的序列号，如果seq大于broker中的序列号+1，那么broker会将消息写入日志，然后更新序列号</span></span><br><span class="line">    <span class="comment">// 如果seq小于broker中的序列号+1，那么broker会直接返回成功，不会写入日志</span></span><br><span class="line">    <span class="comment">// 如果seq大于broker中的序列号+1，那么broker会返回错误</span></span><br><span class="line">    <span class="comment">// !! Kafka幂等只保证单个生产者会话(session)中单个分区内的幂等性，不保证多个分区之间的幂等性</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 如果没有配置以下配置，只需要配置上面的配置即可</span></span><br><span class="line">    <span class="comment">// retry重试次数必须大于0</span></span><br><span class="line">    properties.put(ProducerConfig.RETRIES_CONFIG, <span class="number">10</span>);</span><br><span class="line">    <span class="comment">// acks 必须是 all</span></span><br><span class="line">    properties.put(ProducerConfig.ACKS_CONFIG, <span class="string">&quot;all&quot;</span>);</span><br><span class="line">    <span class="comment">// max.in.flight.requests.per.connection 不能大于5</span></span><br><span class="line">    properties.put(ProducerConfig.MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION, <span class="number">5</span>);</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 事务配置</span></span><br><span class="line"><span class="comment">// 幂等性不能跨分区，如果需要跨分区的幂等性，那么需要使用事务</span></span><br><span class="line"><span class="comment">// 事务可以保证对多个分区写入操作的原子性</span></span><br><span class="line"><span class="comment">// kafka中的事务可以使应用程序将消费消息、生产消息、提交消费位移当做原子操作来处理，同时成功或失败</span></span><br><span class="line"><span class="keyword">static</span> &#123;</span><br><span class="line">    <span class="comment">// 必须提供唯一的transactional.id，如果transactional.id相同，那么会认为是同一个事务</span></span><br><span class="line">    <span class="comment">// 显示设置</span></span><br><span class="line">    properties.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, <span class="string">&quot;transactional-id&quot;</span>);</span><br><span class="line">    <span class="comment">// ！！事务要求生产者开启幂等性</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="如何保证消息顺序"><a href="#如何保证消息顺序" class="headerlink" title="如何保证消息顺序"></a>如何保证消息顺序</h2><ul>
<li><strong>retries</strong> &gt; 0 &amp; <strong>max.in.flight.requests.per.connection</strong> &#x3D; 1</li>
</ul>
<p>​      推荐使用此方式，一定程度上能保证消息不丢失，但是会导致吞吐量下降；</p>
<ul>
<li><strong>retries</strong> &#x3D; 0 &amp; <strong>max.in.flight.requests.per.connection</strong> &gt; 1</li>
</ul>
<p>NetworkClient:</p>
<p><img data-src="/images/message/kafka/01.png" alt="img"></p>
<p>​      </p>
]]></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>消息队列</tag>
        <tag>中间件</tag>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title>pulsar-使用</title>
    <url>/2025/02/09/xiao-xi-dui-lie/pulsar/shi-yong/posts/undefined/</url>
    <content><![CDATA[<h2 id="创建使用"><a href="#创建使用" class="headerlink" title="创建使用"></a>创建使用</h2><ul>
<li>docker 单机创建</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run -d -it \</span><br><span class="line">    -p 6650:6650 \</span><br><span class="line">    -p 8650:8080 \</span><br><span class="line">    -v /Users/wulei/devTools/pulsar/data:/pulsar/data \</span><br><span class="line">    --name pulsar-standalone \</span><br><span class="line">    apachepulsar/pulsar:latest \</span><br><span class="line">    bin/pulsar standalone</span><br></pre></td></tr></table></figure>

<ul>
<li>可视化 pulsar-manager</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker pull apachepulsar/pulsar-manager:v0.3.0</span><br><span class="line">docker run -d -it \</span><br><span class="line">    -p 9527:9527 -p 7750:7750 \</span><br><span class="line">    -e SPRING_CONFIGURATION_FILE=/pulsar-manager/pulsar-manager/application.properties \</span><br><span class="line">    --<span class="built_in">link</span> pulsar-standalone \</span><br><span class="line">    --name pulsar-manager\</span><br><span class="line">    apachepulsar/pulsar-manager:v0.3.0</span><br></pre></td></tr></table></figure>

<ul>
<li>创建 pulsar-manager admin 用户，用户名： admin 密码： apachepulsar</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">CSRF_TOKEN=$(curl http://localhost:7750/pulsar-manager/csrf-token)</span><br><span class="line">curl \</span><br><span class="line">   -H <span class="string">&#x27;X-XSRF-TOKEN: $CSRF_TOKEN&#x27;</span> \</span><br><span class="line">   -H <span class="string">&#x27;Cookie: XSRF-TOKEN=$CSRF_TOKEN;&#x27;</span> \</span><br><span class="line">   -H <span class="string">&quot;Content-Type: application/json&quot;</span> \</span><br><span class="line">   -X PUT http://localhost:7750/pulsar-manager/users/superuser \</span><br><span class="line">   -d <span class="string">&#x27;&#123;&quot;name&quot;: &quot;admin&quot;, &quot;password&quot;: &quot;apachepulsar&quot;, &quot;description&quot;: &quot;test&quot;, &quot;email&quot;: &quot;username@test.org&quot;&#125;&#x27;</span></span><br></pre></td></tr></table></figure>

<ul>
<li>Pulsar-manager 连接 pulsar 集群，注意使用容器名称+容器内部端口进行连接</li>
</ul>
<p><img data-src="/images/message/pulsar/01.png" alt="img"></p>
<ul>
<li>创建租户</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">./bin/pulsar-admin tenants create lei-learn</span><br></pre></td></tr></table></figure>

<ul>
<li>创建 namespace</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">./bin/pulsar-admin namespaces create lei-learn/dev</span><br></pre></td></tr></table></figure>

<ul>
<li>创建 topic</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">/bin/pulsar-admin topics create persistent://lei-learn/dev/string</span><br><span class="line"><span class="comment"># 创建5个分区的topic</span></span><br><span class="line">/bin/pulsar-admin topics create-partitioned-topic -p 5 persistent://lei-learn/dev/string</span><br></pre></td></tr></table></figure>

<ul>
<li>显示某个 namespace 下的 topic</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">/bin/pulsar-admin topics list lei-learn/dev/</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>消息队列</tag>
        <tag>中间件</tag>
        <tag>pulsar</tag>
      </tags>
  </entry>
  <entry>
    <title>spring-kafka</title>
    <url>/2025/02/09/xiao-xi-dui-lie/kafka/spring-kakfa/posts/undefined/</url>
    <content><![CDATA[<blockquote>
<p> Spring kafka 版本 2.8.4</p>
</blockquote>
<h2 id="网站资料"><a href="#网站资料" class="headerlink" title="网站资料"></a>网站资料</h2><ul>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.8.11/reference/html/#message-listener-container">spring-kafka(2.8.11)</a></li>
<li><a href="https://www.baeldung.com/?s=spring+kafka">baeldung-spring-kafka</a></li>
</ul>
<h2 id="offset管理"><a href="#offset管理" class="headerlink" title="offset管理"></a>offset管理</h2><h3 id="Kafka-自动提交-offset"><a href="#Kafka-自动提交-offset" class="headerlink" title="Kafka 自动提交 offset"></a>Kafka 自动提交 offset</h3><ul>
<li>enable.auto.commit&#x3D;true</li>
<li>auto-commit-interval 自动提交的时间间隔</li>
</ul>
<p>​      比如 1s，那么自动提交的时间点 deadline 就是当前时间 +1s，但是自动提交 offset 的线程也是 poll 线程，所以提交 offset 的时间不一定是固定的 1s，会有下面几种情况</p>
<pre><code>  A.  业务处理时间 &gt;= auto-commit-interval  提交 offset 的时间点就是每次 poll 的时候，由于业务处理时间已经大于自定提交间隔，那么每次 poll 的时候当前时间一定大于 deadline，

  所以一定会进行一次 offset 提交（异步提交），这里提交的 offset 区间就是单次拉取消息的数量大小 max.poll.records

  B.  业务处理时间 &lt;&lt; auto-commit-interval  提叫 offset 的时间点可能在第 n 次 poll 的时候（假设 m=业务处理时间，要求  $$n * m$$  &gt; auto-commit-interval），这时候会进行一次一次 offset 提交（异提   交），这里提交的 offset 区间= $$n * $$max.poll.records 
</code></pre>
<ul>
<li>自动提交流程</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">maybeAutoCommitOffsetsAsync</span><span class="params">(<span class="type">long</span> now)</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (autoCommitEnabled) &#123;</span><br><span class="line">        nextAutoCommitTimer.update(now);</span><br><span class="line">        <span class="keyword">if</span> (nextAutoCommitTimer.isExpired()) &#123;</span><br><span class="line">            nextAutoCommitTimer.reset(autoCommitIntervalMs);</span><br><span class="line">            doAutoCommitOffsetsAsync();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><img data-src="/images/message/kafka/02.png" alt="img"></p>
<h3 id="SpringKafka-提交-offset-流程"><a href="#SpringKafka-提交-offset-流程" class="headerlink" title="SpringKafka 提交 offset 流程"></a>SpringKafka 提交 offset 流程</h3><ul>
<li>前置条件： <strong>enable-auto-commit</strong> &#x3D; false</li>
<li>ackMode &#x3D; <em>RECORD</em></li>
</ul>
<p>​      业务消息处理完成之后，即 doInvokeOnMessage 方法之后，会对发送每条消息的 offset 给 broker</p>
<p><img data-src="/images/message/kafka/03.PNG" alt="img"></p>
<ul>
<li>ackMode !&#x3D; <em>RECORD</em></li>
</ul>
<p><img data-src="/images/message/kafka/04.png" alt="img"></p>
<ul>
<li>AckMode 解析</li>
</ul>
<table>
<thead>
<tr>
<th align="left">类型</th>
<th align="left">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><em>RECORD</em></td>
<td align="left">自动提交每条消息处理完后提交 offset监听模式不支持批量，只支持单条消息业务处理完成后向 broker 提交 offset</td>
</tr>
<tr>
<td align="left"><em>BATCH</em></td>
<td align="left">自动提交默认的类型一批消息处理完成后再提交 offset消息处理完成后会记录在 acks 中，再次 poll 的时候会将 akcs 转换为 offset 并提交到 broker</td>
</tr>
<tr>
<td align="left"><em>TIME</em></td>
<td align="left">自动提交经过 ackTime 之后提交 offset消息处理完成后会记录在 acks 中</td>
</tr>
<tr>
<td align="left"><em>COUNT</em></td>
<td align="left">自动提交消息消费数量超过此配置后提交消息处理完成后会记录在 acks 中</td>
</tr>
<tr>
<td align="left"><em>COUNT_TIME</em></td>
<td align="left">自动提交满足 COUNT 或 <em>TIME</em> 时提交 offset</td>
</tr>
<tr>
<td align="left"><em>MANUAL</em></td>
<td align="left">手动提交业务处理后调用 acknowledgment.acknowledge（） 提交 offset（指的是内存中维护的 offset）真正向 broker 提交 offset 还是在下一次 poll（）方法执行时</td>
</tr>
<tr>
<td align="left"><em>MANUAL_IMMEDIATE</em></td>
<td align="left">手动提交业务处理后调用 acknowledgment.acknowledge（） 提交 offset提交 offset 指向 broker 提交 offset，而不是维护内存中的数据</td>
</tr>
</tbody></table>
<h3 id="向-Broker-提交-offset-流程"><a href="#向-Broker-提交-offset-流程" class="headerlink" title="向 Broker 提交 offset 流程"></a>向 Broker 提交 offset 流程</h3><ul>
<li>同步提交 syncCommits&#x3D;true（<strong>默认</strong>）</li>
<li>异步提交 syncCommits&#x3D;false</li>
</ul>
<p><img data-src="/images/message/kafka/05.png" alt="img"></p>
<h2 id="异常处理"><a href="#异常处理" class="headerlink" title="异常处理"></a><a href="https://rq3nt70g815.feishu.cn/wiki/RO2qwqD4YiF4W8kQXmPcos02n8f">异常处理</a></h2><h3 id="默认的异常处理器-DefaultErrorHandler"><a href="#默认的异常处理器-DefaultErrorHandler" class="headerlink" title="默认的异常处理器 DefaultErrorHandler"></a>默认的异常处理器 DefaultErrorHandler</h3><ul>
<li>此处理会重试 n 次，n 次重试都失败后会跳过当前失败的消息，offset 推进一位，所以会导致失败消息丢失！</li>
<li>默认重试 9 次，每次重试之前没有间隔</li>
</ul>
<p><img data-src="/images/message/kafka/06.png" alt="img"></p>
<ul>
<li>业务处理失败 &amp; 重试次数 &lt; 9，抛出异常；会重新 poll 消息进行消费；</li>
</ul>
<p>假设拉取的整批消息中第 n 条消息消费失败（n &gt; 1），那么在消费失败时会先提交 offset，保证前面已经消费的 offset 正常提交</p>
<p><img data-src="/images/message/kafka/07.png" alt="img"></p>
<ul>
<li>定义重试次数 &amp; 重试间隔</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">FixedBackOff</span> <span class="variable">fixedBackOff</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">FixedBackOff</span>(<span class="number">100</span>, <span class="number">1</span>);</span><br><span class="line"><span class="type">DefaultErrorHandler</span> <span class="variable">defaultErrorHandler</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">DefaultErrorHandler</span>(fixedBackOff);</span><br><span class="line">kafkaMessageListenerContainer.setCommonErrorHandler(defaultErrorHandler);</span><br></pre></td></tr></table></figure>

<ul>
<li>批量消费时，遇到异常需要抛出 BatchListenerFailedException，否则会重试整个批次，重试次数过后会越过整个批次的 offset</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 3 指的是失败最小消息的index，重试会从这里开始</span></span><br><span class="line"><span class="type">BatchListenerFailedException</span> <span class="variable">batchListenerFailedException</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">BatchListenerFailedException</span>(<span class="string">&quot;批次消费失败&quot;</span>, <span class="number">3</span>);</span><br><span class="line"><span class="keyword">throw</span> batchListenerFailedException;</span><br></pre></td></tr></table></figure>

<h3 id="优雅的异常处理"><a href="#优雅的异常处理" class="headerlink" title="优雅的异常处理"></a>优雅的异常处理</h3><p>默认的异常处理器重试失败仅仅打印日志，对于系统来说消息就丢失了。</p>
<p>所以需要重写 ConsumerRecordRecoverer 接口，将失败的消息发送到死信队列中，便于后续人工或程序进行处理</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 自定义重试次数 &amp; 重试间隔</span></span><br><span class="line"><span class="type">FixedBackOff</span> <span class="variable">fixedBackOff</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">FixedBackOff</span>(<span class="number">2000</span>, <span class="number">1</span>);</span><br><span class="line"><span class="comment">// 自定义消息recover，针对不同类型的消息，转发到不同的topic中</span></span><br><span class="line"><span class="type">DeadLetterPublishingRecoverer</span> <span class="variable">recoverer</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">DeadLetterPublishingRecoverer</span>(kafkaTemplate, (record, exception) -&gt; &#123;</span><br><span class="line">    log.error(<span class="string">&quot;消息消费失败, topic: &#123;&#125;, partition: &#123;&#125;, offset: &#123;&#125;, data: &#123;&#125;&quot;</span>, record.topic(), record.partition(), record.offset(), record.value());</span><br><span class="line">    <span class="keyword">if</span> (exception.getCause() <span class="keyword">instanceof</span> ArithmeticException) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">TopicPartition</span>(record.topic() + <span class="string">&quot;.arithmetic.failures&quot;</span>, record.partition());</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">TopicPartition</span>(record.topic() + <span class="string">&quot;.other.failures&quot;</span>, record.partition());</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line"><span class="type">DefaultErrorHandler</span> <span class="variable">defaultErrorHandler</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">DefaultErrorHandler</span>(recoverer, fixedBackOff);</span><br></pre></td></tr></table></figure>

<h3 id="版本差异"><a href="#版本差异" class="headerlink" title="版本差异"></a>版本差异</h3><ul>
<li>当前 spring kafka 版本为 2.8.4，这个版本下因为 DefaultErrorHandler  的原因，无论是自动提交还是手动提交，都会 seek 到失败的消息，再进行重试，所以不会出现消费异常时直接提交 offset 的情况；同时此异常处理器对于某条消息处理失败后，不会跳过这条消息是尝试下一条消息消费，所以理论上不会出现消息丢失的情况，只是消费失败仅仅打印日志不友好，需要参考 2。优雅的异常处理 进行处理</li>
<li>在某些早版本的 spring kafka（比如 2.2.4）中，消费失败会直接提交 offset；或者当前这条消息消费失败，下一条消息消费成功后会提交下一条消息的 offset，导致消息丢失；遇到这种情况，以下操作是相对✅的<ul>
<li>autoCommit &#x3D; false</li>
<li>ackMode &#x3D; 手动&#x2F;手动立即</li>
<li>设置错误处理器 SeekToCurrentErrorHandler 更新本地内存拉取 offset 的值为消费失败的 record 的 offset 值，下次 poll 周期就会去重新拉取未提交的 offset。重试 DeadLetterPublishRecover 多次消费失败： 入死信队列，可设置 Topic 名称，默认到 [target_topic]。DLT</li>
</ul>
</li>
</ul>
<p><img data-src="/images/message/kafka/08.png" alt="img"></p>
]]></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>消息队列</tag>
        <tag>中间件</tag>
        <tag>kafka</tag>
        <tag>spring</tag>
      </tags>
  </entry>
</search>
